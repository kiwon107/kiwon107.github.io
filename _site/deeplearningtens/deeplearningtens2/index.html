<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[Deeplearning(Tensorflow)] 2. 심층 신경망 - Wonny’s DevLog</title>
<meta name="description" content="본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">


  <meta name="author" content="K.W. Yang">
  
  <meta property="article:author" content="K.W. Yang">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Wonny's DevLog">
<meta property="og:title" content="[Deeplearning(Tensorflow)] 2. 심층 신경망">
<meta property="og:url" content="http://localhost:4000/deeplearningtens/deeplearningtens2/">


  <meta property="og:description" content="본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">







  <meta property="article:published_time" content="2022-02-26T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/deeplearningtens/deeplearningtens2/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Kiwon Yang",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Wonny's DevLog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
        equationNumbers: {
        autoNumber: "AMS"
        }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
    }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo.png" alt="Wonny's DevLog"></a>
        
        <a class="site-title" href="/">
          Wonny's DevLog
          <span class="site-subtitle">Version 1.0</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/profile.jpg" alt="K.W. Yang" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">K.W. Yang</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>AI Researcher &amp; Developer</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:p2881p@naver.com" rel="me" class="u-email">
            <meta itemprop="email" content="p2881p@naver.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">AI</span>
        

        
        <ul>
          
          
            <li><a href="/machinelearning/">머신러닝(사이킷런) (14)</a></li>
          
          
            <li><a href="/deeplearningpyt/">딥러닝(파이토치) (16)</a></li>
          
          
            <li><a href="/deeplearningtens/">딥러닝(텐서플로우) (9)</a></li>
          
          
            <li><a href="/tensortextbook/">딥러닝 텐서플로 교과서 (1)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Language</span>
        

        
        <ul>
          
          
            <li><a href="/pythonmd/">파이썬 중급 (26)</a></li>
          
          
            <li><a href="/pyconcur/">파이썬 동시성 프로그래밍 (4)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">CS Theory</span>
        

        
        <ul>
          
          
            <li><a href="/os/">운영체제 ()</a></li>
          
          
            <li><a href="/algopy/">자료구조와 알고리즘(파이썬) (2)</a></li>
          
          
            <li><a href="/comm/">네트워크(초급) (22)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Electricity / Electronics</span>
        

        
        <ul>
          
          
            <li><a href="/elecbasic/">전기 기초 (3)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Mathematics</span>
        

        
        <ul>
          
          
            <li><a href="/prob/">확률과 통계 (2)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <a href="/paper/"><span class="nav__sub-title">논문</span></a>
        

        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Deeplearning(Tensorflow)] 2. 심층 신경망">
    <meta itemprop="description" content="본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">
    <meta itemprop="datePublished" content="2022-02-26T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/deeplearningtens/deeplearningtens2/" class="u-url" itemprop="url">[Deeplearning(Tensorflow)] 2. 심층 신경망
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-02-26T00:00:00+09:00">February 26, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#2-1-2개의-층">2-1. 2개의 층</a></li><li><a href="#2-2-심층-신경망-만들기">2-2. 심층 신경망 만들기</a></li><li><a href="#2-3-층을-추가하는-다른-방법">2-3. 층을 추가하는 다른 방법</a></li><li><a href="#2-4-렐루-함수">2-4. 렐루 함수</a></li><li><a href="#2-5-옵티마이저">2-5. 옵티마이저</a></li></ul>

            </nav>
          </aside>
        
        <p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="2-1-2개의-층">2-1. 2개의 층</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">),</span> <span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">test_target</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">fashion_mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">train_scaled</span> <span class="o">=</span> <span class="n">train_input</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">train_scaled</span> <span class="o">=</span> <span class="n">train_scaled</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">train_scaled</span><span class="p">,</span> <span class="n">val_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">val_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<p>1장과 약간 다르게 입력층과 출력층 사이에 밀집층을 추가해볼 것이다. 입력층과 출력층 사이에 있는 모든 층을 <strong>은닉충(Hidden layer)</strong> 라고 한다. 은닉층에도 활성화 함수가 존재한다. 활성화 함수는 신경망 층의 선형 방정식의 계산 값에 적용하는 함수이다. 출력층에서는 이진 분류일 경우 시그모이드 함수, 다중 분류일 경우 소프트맥스 함수로 활성화 함수가 제한되었다. 그러나 은닉층의 활성화 함수는 비교적 자유롭다. 참고로 회귀의 출력은 임의의 어떤 숫자이므로 활성화 함수를 적용하지 않아도 된다.<br />
우리는 왜 은칙층에 활성화 함수를 적용해야 할까? 만약 활성화 함수 없이 선형적인 산술 계산만 은닉층에서 수행한다면, 사실 은닉층이 수행하는 역할은 없는거나 마찬가지다. 선형 계산을 적당하게 비선형으로 비틀어 주어야 나름의 은닉층 역할을 수행할 수 있게 된다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dense1</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="p">))</span>
<span class="n">dense2</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
</code></pre></div></div>

<p>은닉층의 뉴런 개수를 정하는데 특별한 기준은 없다. 몇 개의 뉴런을 두어야 할지 판단하려면 상당한 경험이 필요하다. 그렇지만 한가지 제약사항은 있다. 적어도 출력층의 뉴런보다는 많게 만들어야 한다. 예를 들어, 클래스 10개에 대한 확률을 예측하는데, 이전 은닉층의 뉴런이 10개보다 적다면 부족한 정보가 전달될 것이다.</p>

<h2 id="2-2-심층-신경망-만들기">2-2. 심층 신경망 만들기</h2>
<p>이제 앞에서 만든 dense1과 dense2 객체를 <code class="language-plaintext highlighter-rouge">Sequential</code> 클래스에 추가하여 <strong>심층 신경망(Deep neural network)</strong>을 만들어보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">dense1</span><span class="p">,</span> <span class="n">dense2</span><span class="p">])</span>
</code></pre></div></div>

<p>출력층은 꼭 가장 마지막에 두어야 한다!<br />
케라스 모델의 <code class="language-plaintext highlighter-rouge">summary()</code> 메소드를 호출하여 층에 대한 유용한 정보를 얻어보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Model: "sequential"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       dense_2 (Dense)              (None, 100)               78500     
       _________________________________________________________________
       dense_3 (Dense)              (None, 10)                1010      
       =================================================================
       Total params: 79,510
       Trainable params: 79,510
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>출력을 보면 첫 줄에는 모델 이름이 나온다. 그 다음 모델에 들어 있는 층이 순서대로 나열된다. 층마다 층 이름, 클래스, 출력 크기, 모델 파라미터 개수가 나온다. 층을 만들 때 <code class="language-plaintext highlighter-rouge">name</code> 매개변수로 이름을 지정할 수 있다. 출력 크기를 보면 샘플개수가 정의되어 있지 않아 None으로 나온다. 왜 그럴까? 바로 사용자가 batch_size 매개변수로 미니 배치 개수를 지정할 수 있기 때문이다. 따라서 샘플 개수를 고정하지 않고 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정한다. 이렇게 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 배치 차원 이라고 부른다.<br />
모델 파라미터 개수를 보면 처음에 78,500개가 존재한다. 입력층 784개의 뉴런에 은닉층의 100개 뉴런을 곱하면 78,400개가 된다. 여기에 은닉층 100개 뉴런의 절편 개수까지 더하면 78,500개가 된다. 두번째 파라미터 개수는 100 x 10 + 10 으로 1,010개가 된다! 총 모델 파라미터 개수와 훈련되는 파라미터 개수가 동일하게 79,510개로 나온다. Non-trainable params는 0으로 나오는데, 간혹 경사 하강법으로 훈련되지 않는 파라미터를 가진 층이 있다. 이런 층이 여기에 나타나게 된다.</p>

<h2 id="2-3-층을-추가하는-다른-방법">2-3. 층을 추가하는 다른 방법</h2>
<p>첫번째 방법.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s">'hidden'</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'output'</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span> <span class="o">=</span> <span class="s">'패션 MNIST 모델'</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Model: "패션 MNIST 모델"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       hidden (Dense)               (None, 100)               78500     
       _________________________________________________________________
       output (Dense)               (None, 10)                1010      
       =================================================================
       Total params: 79,510
       Trainable params: 79,510
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>두번째 방법.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,)))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Model: "sequential_1"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       dense_4 (Dense)              (None, 100)               78500     
       _________________________________________________________________
       dense_5 (Dense)              (None, 10)                1010      
       =================================================================
       Total params: 79,510
       Trainable params: 79,510
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>이제 모델을 훈련해보자. <code class="language-plaintext highlighter-rouge">compile()</code> 메소드 설정은 1장과 동일하다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Epoch 1/5
       1500/1500 [==============================] - 4s 3ms/step - loss: 0.5649 - accuracy: 0.8062
       Epoch 2/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.4097 - accuracy: 0.8527
       Epoch 3/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3735 - accuracy: 0.8643
       Epoch 4/5
       1500/1500 [==============================] - 4s 2ms/step - loss: 0.3517 - accuracy: 0.8726
       Epoch 5/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3342 - accuracy: 0.8786
       &lt;tensorflow.python.keras.callbacks.History at 0x18340fc20f0&gt;
</code></pre></div></div>

<p>몇 개의 층을 추가해도 <code class="language-plaintext highlighter-rouge">compile()</code> 메소드와 <code class="language-plaintext highlighter-rouge">fit()</code> 메소드 사용법은 동일하다.</p>

<h2 id="2-4-렐루-함수">2-4. 렐루 함수</h2>
<p class="align-center">시그모이드 함수의 식은 다음과 같다.<br />
$\phi = \frac{1}{1+e^{-x}}$<br />
이를 그래프로 나타내면 다음과 같다.
<img src="/assets/images/deeplearningtens/2-1.png" alt="그림 2-1. 시그모이드 함수" /></p>
<p>그림 2-1. 시그모이드 함수</p>

<p class="align-center">보다시피 오른쪽과 왼쪽 끝으로 갈수록 그래프가 누워있다. 그러므로 올바른 출력을 만드는데 신속한 대응이 어렵다. 특히 층이 많은 심층 신경망에서는 그 효과가 누적되어 학습을 더 어렵게 만든다.<br />
<strong>렐루(ReLU)</strong> 함수는 이러한 문제를 해결해준다. 입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력을 통과시키고 음수일 경우 0으로 만든다.
<img src="/assets/images/deeplearningtens/2-2.png" alt="그림 2-2. 렐루 함수" /></p>
<p>그림 2-2. 렐루 함수</p>

<p>렐루 함수는 max(0,z)로 표현할 수 있다. z가 0보다 크면 z를 출력하고 0보다 작으면 0을 출력한다. 렐루 함수는 이미지 처리에서 특히 좋은 성능을 낸다고 알려져 있다.<br /></p>

<p>지금까지 1차원 형태로 이미지를 변형할 때 우리는 <code class="language-plaintext highlighter-rouge">reshape()</code> 메소드를 활용했다. 케라스에서는 <code class="language-plaintext highlighter-rouge">Flatten</code> 층을 제공해준다. <code class="language-plaintext highlighter-rouge">Flatten</code> 클래스는 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼치는 역할만 한다. 입력에 곱해지는 가중치나 절편은 전혀 없다. 입력층 바로 뒤에 Flatten 층을 추가해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Model: "sequential_2"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       flatten (Flatten)            (None, 784)               0         
       _________________________________________________________________
       dense_6 (Dense)              (None, 100)               78500     
       _________________________________________________________________
       dense_7 (Dense)              (None, 10)                1010      
       =================================================================
       Total params: 79,510
       Trainable params: 79,510
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>Flatten 층이 학습하는 층이 아니므로 모델 파라미터는 0개이다.<br />
이제 해당 모델로 훈련 시켜보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">),</span> <span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">teset_target</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">fashion_mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_scaled</span> <span class="o">=</span> <span class="n">train_input</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">train_scaled</span><span class="p">,</span> <span class="n">val_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">val_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Epoch 1/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.5275 - accuracy: 0.8127
       Epoch 2/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3914 - accuracy: 0.8594: 0s - loss:
       Epoch 3/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3521 - accuracy: 0.8724
       Epoch 4/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3327 - accuracy: 0.8812: 0s - loss: 0.3317 - accuracy: 
       Epoch 5/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3160 - accuracy: 0.8865
       &lt;tensorflow.python.keras.callbacks.History at 0x18340930898&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">val_scaled</span><span class="p">,</span> <span class="n">val_target</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 375/375 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8764
       [0.3613932430744171, 0.8764166831970215]
</code></pre></div></div>

<p>시그모이드 함수를 사용했을 때보다 성능이 조금 더 향상됐다.</p>

<h2 id="2-5-옵티마이저">2-5. 옵티마이저</h2>
<p>케라스는 기본적으로 미니배치 경사 하강법을 사용하며 미니배치 개수는 32개이다. <code class="language-plaintext highlighter-rouge">fit()</code> 메소드의 <code class="language-plaintext highlighter-rouge">batch_size</code> 매개변수에서 이를 조정할 수 있다. <code class="language-plaintext highlighter-rouge">compile()</code> 메소드에서 우리는 <code class="language-plaintext highlighter-rouge">loss</code>와 <code class="language-plaintext highlighter-rouge">metric</code> 매개변수를 건들었다. 그러나 이 외에도 케라스는 다양한 종류의 경사 하강법 알고리즘을 <code class="language-plaintext highlighter-rouge">compile()</code> 메소드를 통해 제공한다. 이들을 <strong>옵티마이저(Optimizer)</strong> 라고 부른다.<br />
가장 기본적인 옵티마이저는 SGD 이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'SGD'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
</code></pre></div></div>

<p>위 코드는 다음 코드와 완전히 동일하다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sgd</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="n">SGD</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
</code></pre></div></div>

<p>만약 SGD의 학습률을 바꾸고 싶다면 다음과 같이 <code class="language-plaintext highlighter-rouge">learning_rate</code> 매개변수에서 지정하자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sgd</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></div>

<p>SGD외에도 여러 옵티마이저들이 있다. <code class="language-plaintext highlighter-rouge">SGD</code> 클래스의 <code class="language-plaintext highlighter-rouge">momentum</code> 매개변수는 기본값이 0이다. 0보다 큰 값으로 지정하면 마치 이전의 그레이디언트를 가속도처럼 사용하는 <strong>모멘텀 최적화(Momentum optimization)</strong>를 사용하게 된다. 보통 0.9이상의 값을 주어 사용한다. <code class="language-plaintext highlighter-rouge">SGD</code> 클래스의 <code class="language-plaintext highlighter-rouge">nesterov</code> 매개변수를 기본값 False에서 True로 바꾸면 <strong>네스테로프 모멘텀 최적화(Nesterov momentum optimization)</strong>을 사용한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sgd</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimization</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>네스테로프 모멘텀은 최적화를 2번 반복하여 구현한다. 보통 네스테로프 모멘텀 최적화가 기본 SGD보다 더 나은 성능을 보여준다.<br />
모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다. 안정적으로 최적점 수렴에 도달할 가능성이 높다. 이런 학습률을 <strong>적응적 학습률(Adaptive learning rate)</strong>라고 한다. 학습률 매개변수를 튜닝하는 수고를 덜 수 있다는게 장점이다. 대표적인 옵티마이저로는 <code class="language-plaintext highlighter-rouge">Adagrad</code>와 <code class="language-plaintext highlighter-rouge">RMSprop</code>이 있다. 기본값은 <code class="language-plaintext highlighter-rouge">RMSprop</code>이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">adagrad</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adagrad</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">adagrad</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">rmsprop</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">RMSprop</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">rmsprop</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
</code></pre></div></div>

<p>참고로 모멘텀 최적화와 RMSProp 장점을 접목한 것이 Adam이다. 케라스는 <code class="language-plaintext highlighter-rouge">Adam</code> 클래스도 제공하며 <code class="language-plaintext highlighter-rouge">learning_rate</code> 매개변수의 기본값은 모두 0.001이다. <code class="language-plaintext highlighter-rouge">adam</code>으로 모델을 훈련시켜보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Epoch 1/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.5268 - accuracy: 0.8141
       Epoch 2/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3917 - accuracy: 0.8584
       Epoch 3/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3528 - accuracy: 0.8712
       Epoch 4/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3269 - accuracy: 0.8799
       Epoch 5/5
       1500/1500 [==============================] - 3s 2ms/step - loss: 0.3092 - accuracy: 0.8868
       &lt;tensorflow.python.keras.callbacks.History at 0x18340a10e10&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">val_scaled</span><span class="p">,</span> <span class="n">val_target</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 375/375 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8719
       [0.3467445373535156, 0.871916651725769]
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#deep-learning" class="page__taxonomy-item p-category" rel="tag">deep learning</a><span class="sep">, </span>
    
      <a href="/tags/#deep-neural-network" class="page__taxonomy-item p-category" rel="tag">deep neural network</a><span class="sep">, </span>
    
      <a href="/tags/#optimizer" class="page__taxonomy-item p-category" rel="tag">optimizer</a><span class="sep">, </span>
    
      <a href="/tags/#relu-function" class="page__taxonomy-item p-category" rel="tag">relu function</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#deeplearningtens" class="page__taxonomy-item p-category" rel="tag">deeplearningtens</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-02-26T00:00:00+09:00">February 26, 2022</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/deeplearningtens/deeplearningtens1/" class="pagination--pager" title="[Deeplearning(Tensorflow)] 1. 인공 신경망
">Previous</a>
    
    
      <a href="/deeplearningtens/deeplearningtens3/" class="pagination--pager" title="[Deeplearning(Tensorflow)] 3. 신경망 모델 훈련
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/comm/comm22/" rel="permalink">[네트워크 초급] 22. 라우터의 구조
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-05-24T00:00:00+09:00">May 24, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “모두의 네트워크” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/comm/comm21/" rel="permalink">[네트워크 초급] 21. 서브넷의 구조
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-05-18T00:00:00+09:00">May 18, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “모두의 네트워크” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/comm/comm20/" rel="permalink">[네트워크 초급] 20. 네트워크 주소와 브로드캐스트 주소의 구조
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-05-18T00:00:00+09:00">May 18, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “모두의 네트워크” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/comm/comm19/" rel="permalink">[네트워크 초급] 19. IP 주소의 클래스 구조
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-05-17T00:00:00+09:00">May 17, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “모두의 네트워크” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
          <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-gitlab" aria-hidden="true"></i> GitLab</a></li>
        
      
        
      
        
          <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Kiwon Yang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'kiwon107/kiwon107.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  





  </body>
</html>
