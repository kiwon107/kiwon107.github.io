<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[Deeplearning(Tensorflow)] 9. LSTM과 GRU 셀 - Wonny’s DevLog</title>
<meta name="description" content="본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">


  <meta name="author" content="K.W. Yang">
  
  <meta property="article:author" content="K.W. Yang">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Wonny's DevLog">
<meta property="og:title" content="[Deeplearning(Tensorflow)] 9. LSTM과 GRU 셀">
<meta property="og:url" content="http://localhost:4000/deeplearningtens/deeplearningtens9/">


  <meta property="og:description" content="본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">







  <meta property="article:published_time" content="2022-03-03T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/deeplearningtens/deeplearningtens9/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Kiwon Yang",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Wonny's DevLog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
        equationNumbers: {
        autoNumber: "AMS"
        }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
    }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo.png" alt="Wonny's DevLog"></a>
        
        <a class="site-title" href="/">
          Wonny's DevLog
          <span class="site-subtitle">Version 1.0</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/profile.jpg" alt="K.W. Yang" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">K.W. Yang</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>AI Researcher &amp; Developer</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:p2881p@naver.com" rel="me" class="u-email">
            <meta itemprop="email" content="p2881p@naver.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">AI</span>
        

        
        <ul>
          
          
            <li><a href="/machinelearning/">머신러닝(사이킷런) (14)</a></li>
          
          
            <li><a href="/deeplearningpyt/">딥러닝(파이토치) (13)</a></li>
          
          
            <li><a href="/deeplearningtens/">딥러닝(텐서플로우) (9)</a></li>
          
          
            <li><a href="/tensortextbook/">딥러닝 텐서플로 교과서 (1)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Language</span>
        

        
        <ul>
          
          
            <li><a href="/pythonmd/">파이썬 중급 (26)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">CS Theory</span>
        

        
        <ul>
          
          
            <li><a href="/os/">운영체제 ()</a></li>
          
          
            <li><a href="/algopy/">자료구조와 알고리즘(파이썬) (1)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Mathematics</span>
        

        
        <ul>
          
          
            <li><a href="/prob/">확률과 통계 (2)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <a href="/paper/"><span class="nav__sub-title">논문</span></a>
        

        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Deeplearning(Tensorflow)] 9. LSTM과 GRU 셀">
    <meta itemprop="description" content="본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">
    <meta itemprop="datePublished" content="2022-03-03T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/deeplearningtens/deeplearningtens9/" class="u-url" itemprop="url">[Deeplearning(Tensorflow)] 9. LSTM과 GRU 셀
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-03T00:00:00+09:00">March 3, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#9-1-lstm-구조">9-1. LSTM 구조</a></li><li><a href="#9-2-lstm-신경망-훈련하기">9-2. LSTM 신경망 훈련하기</a></li><li><a href="#9-3-순환층에-드롭아웃-적용하기">9-3. 순환층에 드롭아웃 적용하기</a></li><li><a href="#9-4-2개의-층을-연결하기">9-4. 2개의 층을 연결하기</a></li><li><a href="#9-5-gru-구조">9-5. GRU 구조</a></li><li><a href="#9-6-gru-신경망-훈련하기">9-6. GRU 신경망 훈련하기</a></li></ul>

            </nav>
          </aside>
        
        <p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="9-1-lstm-구조">9-1. LSTM 구조</h2>
<p><strong>LSTM(Long Shor-Term Memory)</strong>는 단기 기억을 오래 기억하기 위해 고안되었다. LSTM에는 입력과 가중치를 곱하고 절편을 더해 활성화 함수를 통과시키는 구조를 여러개 가지고 있다. 이런 계산 결과는 다음 타임스텝에 재사용 된다.</p>

<p class="align-center">은닉상태를 먼저 보자. 은닉 상태는 입력과 이전 타임스텝의 은닉 상태를 가중치에 곱한 후 활성화 함수를 통과시켜 다음 은닉 상태를 만든다. 이 때 활성화 함수르 시그모이드 활성화 함수를 사용한다. 또 tanh 활성화 함수를 통과한 어떤 값과 곱해져서 은닉 상태를 만든다. 앞으로 나올 기호 중, 편의상 은닉 상태 계산시 가중치 $w_{x}$ 와 $w_{h}$ 를 통틀어 $w_{o}$ 라고 하자.
<img src="/assets/images/deeplearningtens/9-1.png" alt="그림 9-1. LSTM 구조" /></p>
<p>그림 9-1. LSTM 구조</p>

<p class="align-center"><img src="/assets/images/deeplearningtens/9-2.png" alt="그림 9-2. LSTM 수식" /></p>
<p>그림 9-2. LSTM 수식</p>

<p>LSTM에는 순환되는 상태가 2개다. 은닉 상태 말고 <strong>셀 상태(Cell state)</strong>라고 부르는 값이 따로 있다. 셀 상태는 다음 층으로 전달되지 않고 LSTM 셀에만 순환되는 값이다. 은닉 상태 h와 구분지어 c로 표시하자. 셀 상태를 계산하는 과정은 다음과 같다.</p>

<p>먼저 입력과 은닉 상태를 또 다른 가중치 $w_{f}$ 에 곱한 다음 시그모이드 함수를 통과시킨다. 그 다음 이전 타임스텝의 셀 상태와 곱하여 새로운 셀 상태를 만든다. 이 셀 상태가 오른쪽 tanh 함수를 통과하여 새로운 은닉 상태를 만드는데 기여한다. 중요한 것은 입력과 은닉 상태에 곱해지는 가중치 $w_{o}$와 $w_{f}$ 가 다르다는 것이다. 이 두 작은 셀은 각기 다른 기능을 위해 훈련된다.</p>

<p>여기에 2개의 작은 셀이 추가되어 셀 상태를 만드는데 기여한다. 이전처럼 입력과 은닉 상태를 각기 다른 가중치에 곱한 다음, 하나는 시그모이드 함수를 통과시키고 다른 하나는 tanh 함수를 통과시킨다. 그 다음 두 결과를 곱한 후 이전 셀 상태와 더한다. 이 결과가 최종적인 다음 셀 상태가 된다.</p>

<p>그림 9-1 처럼 세 군데의 곱셈을 왼쪽부터 차례대로 삭제 게이트, 입력 게이트, 출력 게이트 라고 부른다. 삭제 게이트는 셀 상태에 있는 정보를 제거하는 역할을 하고, 입력 게이트는 새로운 정보를 셀 상태에 추가한다. 출력 게이트를 통해 이 셀 상태가 다음 은닉 상태로 출력된다.</p>

<h2 id="9-2-lstm-신경망-훈련하기">9-2. LSTM 신경망 훈련하기</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">imdb</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">),</span> <span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">test_target</span><span class="p">)</span> <span class="o">=</span> <span class="n">imdb</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">train_input</span><span class="p">,</span> <span class="n">val_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">val_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="n">train_seq</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">val_seq</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">val_input</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Model: "sequential"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       embedding (Embedding)        (None, 100, 16)           8000      
       _________________________________________________________________
       lstm (LSTM)                  (None, 8)                 800       
       _________________________________________________________________
       dense (Dense)                (None, 1)                 9         
       =================================================================
       Total params: 8,809
       Trainable params: 8,809
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>SimpleRNN 클래스의 모델 파라미터 개수는 200개였다. LSTM 셀에는 작은 셀이 4개가 있으므로 정확히 4배가 늘어 모델 파라미터 개수는 800개가 되었다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rmsprop</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">rmsprop</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s">'best-lstm-model.h5'</span><span class="p">)</span>
<span class="n">early_stopping_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">restore_best_weights</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_seq</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_seq</span><span class="p">,</span> <span class="n">val_target</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb</span><span class="p">,</span> <span class="n">early_stopping_cb</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Epoch 1/100
       313/313 [==============================] - 16s 52ms/step - loss: 0.6926 - accuracy: 0.5432 - val_loss: 0.6919 - val_accuracy: 0.5836
       Epoch 2/100
       ...
       Epoch 42/100
       313/313 [==============================] - 15s 49ms/step - loss: 0.3978 - accuracy: 0.8206 - val_loss: 0.4283 - val_accuracy: 0.8026
       Epoch 43/100
       313/313 [==============================] - 16s 51ms/step - loss: 0.3973 - accuracy: 0.8217 - val_loss: 0.4273 - val_accuracy: 0.8074
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/9-3.png" alt="그림 9-3. 코드 결과" /></p>
<p>그림 9-3. 코드 결과</p>

<h2 id="9-3-순환층에-드롭아웃-적용하기">9-3. 순환층에 드롭아웃 적용하기</h2>
<p>완전 연결 신경망과 합성곱 신경망에서는 Dropout 클래스를 사용하여 드롭아웃을 적용했다. 순환층은 자체적으로 드롭아웃 기능을 제공한다. SimpleRNN과 LSTM 클래스 모두 <code class="language-plaintext highlighter-rouge">dropout</code> 매개변수와 <code class="language-plaintext highlighter-rouge">recurrent_dropout</code> 매개변수를 갖는다. <code class="language-plaintext highlighter-rouge">dropout</code> 매개변수는 셀의 입력에 드롭아웃을 적용한다. <code class="language-plaintext highlighter-rouge">recurrent_dropout</code>은 순환되는 은닉 상태에 드롭아웃을 적용한다. 기술적인 문제로 인해 <code class="language-plaintext highlighter-rouge">recurrent_dropout</code>을 사용하면 GPU를 사용하여 모델을 훈련하지 못한다. 이 때문에 모델의 훈련 속도가 크게 느려진다. 여기에서는 <code class="language-plaintext highlighter-rouge">dropout</code>만 사용해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model2</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layerse</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

<span class="n">rmsprop</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">model2</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">rmsprop</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s">'best-dropout-model.h5'</span><span class="p">)</span>
<span class="n">early_stopping_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">restore_best_weights</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model2</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_seq</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_seq</span><span class="p">,</span> <span class="n">val_target</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb</span><span class="p">,</span> <span class="n">early_stopping_cb</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Epoch 1/100
       313/313 [==============================] - 18s 57ms/step - loss: 0.6928 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5452
       Epoch 2/100
       313/313 [==============================] - 16s 50ms/step - loss: 0.6910 - accuracy: 0.5778 - val_loss: 0.6899 - val_accuracy: 0.6154
       ...
       Epoch 44/100
       313/313 [==============================] - 29s 94ms/step - loss: 0.4110 - accuracy: 0.8140 - val_loss: 0.4284 - val_accuracy: 0.8038
       Epoch 45/100
       313/313 [==============================] - 25s 81ms/step - loss: 0.4107 - accuracy: 0.8110 - val_loss: 0.4288 - val_accuracy: 0.8004
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/9-4.png" alt="그림 9-4. 코드 결과" /></p>
<p>그림 9-4. 코드 결과</p>

<p>드롭아웃의 효과가 발휘된 것으로 보인다. 훈련 손실과 검증 손실 간 차이가 좁혀진 것을 볼 수 있다.</p>

<h2 id="9-4-2개의-층을-연결하기">9-4. 2개의 층을 연결하기</h2>
<p>순환층 연결시 주의할 점이 있다. 순환층의 은닉 상태는 샘플의 마지막 타임스텝에 대한 은닉 상태만 다음 층으로 전달된다. 하지만 순환층을 쌓게 되면 모든 순환층에 순차 데이터가 필요하다. 따라서 앞쪽의 순환층이 모든 타임스텝에 대한 은닉 상태를 출력해야 한다. 오직 마지막 순환층만 마지막 타임스텝의 은닉 상태를 출력해야 한다. 케라스의 순환층에서 모든 타임스텝의 은닉 상태를 출력하려면 마지막을 제외한 다른 모든 순환층에서 <code class="language-plaintext highlighter-rouge">return_sequences</code> 매개변수를 True로 지정하면 된다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model3</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

<span class="n">model3</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Model: "sequential_4"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       embedding_4 (Embedding)      (None, 100, 16)           8000      
       _________________________________________________________________
       lstm_3 (LSTM)                (None, 100, 8)            800       
       _________________________________________________________________
       lstm_4 (LSTM)                (None, 8)                 544       
       _________________________________________________________________
       dense_2 (Dense)              (None, 1)                 9         
       =================================================================
       Total params: 9,353
       Trainable params: 9,353
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>모델 파라미터 개수는 각각 500 x 16 = 8000, (16 x 8 + 8 x 8 + 8) x 4 = 800, (8 x 8 + 8 x 8 + 8) x 4 = 544, 8 x 1 + 1 = 9 로 산출된다. 첫 번째 LSTM 층을 보면 모든 타임스텝 100개의 은닉 상태를 출력하므로 출력 크기가 (None, 100, 8)로 표시되었다. 그러나 두 번째 LSTM층은 마지막 타임스텝의 은닉 상태만 출력하므로 (None, 8) 이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rmsprop</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">model3</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">rmsprop</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s">'best-2rnn-model.h5'</span><span class="p">)</span>
<span class="n">earlystopping_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">restore_best_weights</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model3</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_seq</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_seq</span><span class="p">,</span> <span class="n">val_target</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb</span><span class="p">,</span> <span class="n">earlystopping_cb</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Epoch 1/100
       313/313 [==============================] - 40s 127ms/step - loss: 0.6921 - accuracy: 0.5325 - val_loss: 0.6910 - val_accuracy: 0.5930
       Epoch 2/100
       313/313 [==============================] - 37s 120ms/step - loss: 0.6863 - accuracy: 0.6000 - val_loss: 0.6787 - val_accuracy: 0.6614
       ...
       Epoch 38/100
       313/313 [==============================] - 37s 119ms/step - loss: 0.4212 - accuracy: 0.8061 - val_loss: 0.4350 - val_accuracy: 0.7972
       Epoch 39/100
       313/313 [==============================] - 37s 117ms/step - loss: 0.4212 - accuracy: 0.8065 - val_loss: 0.4375 - val_accuracy: 0.7954
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/9-5.png" alt="그림 9-5. 코드 결과" /></p>
<p>그림 9-5. 코드 결과</p>

<p>과대적합을 제어하면서 손실을 최대한 낮췄다.</p>

<h2 id="9-5-gru-구조">9-5. GRU 구조</h2>
<p class="align-center"><strong>GRU(Gated Recurrent Unit)</strong>은 LSTM을 간소화한 버전으로 생각할 수 있다. 이 셀은 LSTM 처럼 셀 상태를 계산하지 않고 은닉 상태 하나만 포함한다.
<img src="/assets/images/deeplearningtens/9-6.png" alt="그림 9-6. GRU 구조" /></p>
<p>그림 9-6. GRU 구조</p>

<p class="align-center"><img src="/assets/images/deeplearningtens/9-7.png" alt="그림 9-7. GRU 수식" /></p>
<p>그림 9-7. GRU 수식</p>

<p>GRU 셀에는 은닉 상태와 입력에 가중치를 곱하고 절편을 더하는 작은 셀이 3개 들어 있다. 2개는 시그모이드 활성화 함수를 사용하고, 하나는 tanh 활성화 함수를 사용한다. 여기에서도 은닉 상태와 입력에 곱해지는 가중치를 합쳐서 나타냈다. 맨 왼쪽 $w_{z}$ 를 사용하는 셀의 출력이 은닉 상태에 바로 곱해져 삭제 게이트 역할을 수행한다. 이와 똑같은 출력을 1에서 뺀 다음 가장 오른쪽 $w_{g}$를 사용하는 셀의 출력에 곱한다. 이는 입력되는 정보를 제어하는 역할을 수행한다. $w_{r}$을 사용하는 셀에서 출력된 값은 $w_{g}$ 셀이 사용할 은닉 상태의 정보를 제어한다. GRU 셀은 LSTM 보다 가중치가 적기 때문에 계산량이 적지만 LSTM 못지않는 좋은 성능을 내는 것으로 알려졌다.</p>

<h2 id="9-6-gru-신경망-훈련하기">9-6. GRU 신경망 훈련하기</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model4</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

<span class="n">model4</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Model: "sequential_5"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       embedding_5 (Embedding)      (None, 100, 16)           8000      
       _________________________________________________________________
       gru (GRU)                    (None, 8)                 624       
       _________________________________________________________________
       dense_3 (Dense)              (None, 1)                 9         
       =================================================================
       Total params: 8,633
       Trainable params: 8,633
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>GRU 층의 모델 파라미터 개수를 계산해보자. GRU 셀에는 3개의 작은 셀이 있으므로 (16 x 8 + 8 x 8 + 8) x 3 = 600개가 있다. 여기에 한가지가 더 있다. 사실 $w_{g}$ 로 표현된게 $w_{x}$ 와 $w_{h}$ 로 나눠진다. 이렇게 나누어 계산하면 $h_{t-1}$에 곱해지는 절편이 별도로 필요하다. 곱해지는 항마다 하나씩 절편이 추가되는데 뉴런이 8개 있으므로 총 24개의 모델 파라미터가 더해진다. 텐서플로가 이런 계산 방식을 사용하는 이유는 GPU를 잘 활용하기 위해서이다. 널리 통용되는 이론과 구현이 종종 차이가 날 수 있으니 GRU 층의 모델 파라미터 개수를 혼동하지 말자!</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rmsprop</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">model4</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">rmsprop</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s">'best-gru-model.h5'</span><span class="p">)</span>
<span class="n">earlystopping_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">restore_best_weights</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model4</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_seq</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_seq</span><span class="p">,</span> <span class="n">val_target</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb</span><span class="p">,</span> <span class="n">early_stopping_cb</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Epoch 1/100
       313/313 [==============================] - 26s 84ms/step - loss: 0.6921 - accuracy: 0.5469 - val_loss: 0.6912 - val_accuracy: 0.5688
       Epoch 2/100
       313/313 [==============================] - 27s 85ms/step - loss: 0.6900 - accuracy: 0.5736 - val_loss: 0.6889 - val_accuracy: 0.5796
       ...
       Epoch 34/100
       313/313 [==============================] - 21s 68ms/step - loss: 0.4184 - accuracy: 0.8142 - val_loss: 0.4478 -     val_accuracy: 0.7958
       Epoch 35/100
       313/313 [==============================] - 22s 69ms/step - loss: 0.4177 - accuracy: 0.8141 - val_loss: 0.4511 - val_accuracy: 0.7884
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/9-8.png" alt="그림 9-8. 코드 결과" /></p>
<p>그림 9-8. 코드 결과</p>

<p>드롭아웃을 사용하지 않아 이전보다 훈련 손실과 검증 손실 사이에 차이가 있지만 훈련 과정이 잘 수렴되고 있는 것을 확인할 수 있다.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#cell-state" class="page__taxonomy-item p-category" rel="tag">cell state</a><span class="sep">, </span>
    
      <a href="/tags/#deep-learning" class="page__taxonomy-item p-category" rel="tag">deep learning</a><span class="sep">, </span>
    
      <a href="/tags/#gru" class="page__taxonomy-item p-category" rel="tag">GRU</a><span class="sep">, </span>
    
      <a href="/tags/#lstm" class="page__taxonomy-item p-category" rel="tag">LSTM</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#deeplearningtens" class="page__taxonomy-item p-category" rel="tag">deeplearningtens</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-03-03T00:00:00+09:00">March 3, 2022</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/deeplearningtens/deeplearningtens8/" class="pagination--pager" title="[Deeplearning(Tensorflow)] 8. 순환 신경망으로 IMDB 리뷰 분류하기
">Previous</a>
    
    
      <a href="/deeplearningpyt/deeplearningpyt9/" class="pagination--pager" title="[Deeplearning(pytorch)] 9. 오토인코더 기초와 오토인코더 기반 이미지 특징 추출
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningpyt/deeplearningpyt13/" rel="permalink">[Deeplearning(pytorch)] 13. 딥러닝을 해킹하는 적대적 공격
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-26T00:00:00+09:00">March 26, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningpyt/deeplearningpyt12/" rel="permalink">[Deeplearning(pytorch)] 12. Seq2Seq 기계 번역
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-21T00:00:00+09:00">March 21, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningpyt/deeplearningpyt11/" rel="permalink">[Deeplearning(pytorch)] 11. RNN 개요와 영화 리뷰 감정 분석
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-11T00:00:00+09:00">March 11, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningpyt/deeplearningpyt10/" rel="permalink">[Deeplearning(pytorch)] 10. 오토인코더로 망가진 이미지 복원하기
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-11T00:00:00+09:00">March 11, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
          <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-gitlab" aria-hidden="true"></i> GitLab</a></li>
        
      
        
      
        
          <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Kiwon Yang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'kiwon107/kiwon107.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  





  </body>
</html>
