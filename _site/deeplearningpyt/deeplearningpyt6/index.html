<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[Deeplearning(pytorch)] 6. 과대적합과 드롭아웃 - Wonny’s DevLog</title>
<meta name="description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">


  <meta name="author" content="K.W. Yang">
  
  <meta property="article:author" content="K.W. Yang">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Wonny's DevLog">
<meta property="og:title" content="[Deeplearning(pytorch)] 6. 과대적합과 드롭아웃">
<meta property="og:url" content="http://localhost:4000/deeplearningpyt/deeplearningpyt6/">


  <meta property="og:description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">







  <meta property="article:published_time" content="2022-02-06T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/deeplearningpyt/deeplearningpyt6/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Kiwon Yang",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Wonny's DevLog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
        equationNumbers: {
        autoNumber: "AMS"
        }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
    }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo.png" alt="Wonny's DevLog"></a>
        
        <a class="site-title" href="/">
          Wonny's DevLog
          <span class="site-subtitle">Version 1.0</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/profile.jpg" alt="K.W. Yang" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">K.W. Yang</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>AI Researcher &amp; Developer</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:p2881p@naver.com" rel="me" class="u-email">
            <meta itemprop="email" content="p2881p@naver.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">AI</span>
        

        
        <ul>
          
          
            <li><a href="/machinelearning/">머신러닝(사이킷런) (14)</a></li>
          
          
            <li><a href="/deeplearningpyt/">딥러닝(파이토치) (16)</a></li>
          
          
            <li><a href="/deeplearningtens/">딥러닝(텐서플로우) (9)</a></li>
          
          
            <li><a href="/tensortextbook/">딥러닝 텐서플로 교과서 (1)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Language</span>
        

        
        <ul>
          
          
            <li><a href="/pythonmd/">파이썬 중급 (26)</a></li>
          
          
            <li><a href="/pyconcur/">파이썬 동시성 프로그래밍 (4)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">CS Theory</span>
        

        
        <ul>
          
          
            <li><a href="/os/">운영체제 ()</a></li>
          
          
            <li><a href="/algopy/">자료구조와 알고리즘(파이썬) (2)</a></li>
          
          
            <li><a href="/comm/">네트워크(초급) (22)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Electricity / Electronics</span>
        

        
        <ul>
          
          
            <li><a href="/elecbasic/">전기 기초 (3)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Mathematics</span>
        

        
        <ul>
          
          
            <li><a href="/prob/">확률과 통계 (2)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <a href="/paper/"><span class="nav__sub-title">논문</span></a>
        

        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Deeplearning(pytorch)] 6. 과대적합과 드롭아웃">
    <meta itemprop="description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">
    <meta itemprop="datePublished" content="2022-02-06T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/deeplearningpyt/deeplearningpyt6/" class="u-url" itemprop="url">[Deeplearning(pytorch)] 6. 과대적합과 드롭아웃
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-02-06T00:00:00+09:00">February 6, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#6-1-과대적합-과소적합-조기종료">6-1. 과대적합, 과소적합, 조기종료</a></li><li><a href="#6-2-데이터-늘리기">6-2. 데이터 늘리기</a></li><li><a href="#6-3-드롭아웃">6-3. 드롭아웃</a></li></ul>

            </nav>
          </aside>
        
        <p>본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="6-1-과대적합-과소적합-조기종료">6-1. 과대적합, 과소적합, 조기종료</h2>
<p>머신러닝 모델을 만들면 학습 성능은 잘 나오지만, 테스트셋이나 실제 상황에서는 성능이 나오지 않을 때가 있다. 이것을 <strong>과대적합(Overfitting)</strong> 이라고 한다. 즉, 너무 학습 데이터에만 치중되어 새로운 데이터에 대해서는 성능이 잘 나오지 않는 상황을 말한다. 반대로, 학습을 제대로 진행하지 않은 상황을 <strong>과소적합(Underfitting)</strong> 이라고 한다. 이 경우는 학습 데이터도 제대로 학습하지 않는 경우이다.<br />
가장 베스트인 상태는, 과소적합과 과대적합의 중간이다. 학습 데이터와 학습하지 않은 실제 데이터에서 동시에 높은 성능을 내는 상태가 바로 <strong>일반화(Generalization)</strong> 라고 한다.<br /></p>

<p>5장에서, 머신러닝에서는 보통 데이터셋을 학습, 검증, 테스트셋으로 나눈다고 하였다. 이는 과대적합, 과소적합을 탐지하려는 노력의 일환이다. 학습 데이터셋으로 계속 학습하면 오차는 무한정 내려가게 된다. 그러다 보면, 학습 성능은 계속 좋아지지만, 검증/테스트 성능은 오히려 떨이지는 것을 확인할 수 있다. 따라서! 학습 중간중간 검증용 데이터셋으로 모델이 학습 데이터에만 과대적합되지 않았는지 확인이 필요하다!<br />
검증 데이터셋에 대한 성능이 나빠지기 시작하면, 직전이 가장 적합한 모델이라고 할 수 있다. 이 타이밍에 모델을 저장해서 이용하는 것을 조기 종료(Early stopping) 이라고 한다. 즉, 검증 오차가 올라가는 순간을 포착해서 학습을 종료하는 것이다.</p>

<p>과대적합을 막는 방법은 <strong>학습 데이터를 늘리는 방법</strong>과 <strong>드롭아웃을 적용하는 방법</strong>이 있다.</p>

<h2 id="6-2-데이터-늘리기">6-2. 데이터 늘리기</h2>
<p>궁극적으로, 세상의 모든 데이터를 모으는 것이 가장 효과가 좋다(모으기가 힘들뿐…). 새로운 데이터를 얻기가 어렵다면, 이미 가진 데이터를 최대한 늘리는 방법(Data Augmentaion)을 찾아야 한다. 이미지 데이터라면 이미지 일부를 자르거나, 돌리거나, 노이즈를 더하거나, 색상을 변경하는 등 여러가지 방법을 사용할 수 있다. 예제에서는 가로 대칭이동(왼쪽, 오른쪽 뒤집기) 전략을 써먹어 보자. 토치비전의 <code class="language-plaintext highlighter-rouge">transform</code> 패키지를 사용하면 간단하다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">datasets</span>

<span class="n">USE_CUDA</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">USE_CUDA</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>

<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span>
  <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s">'./.data'</span><span class="p">,</span>
                  <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                  <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                  <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
                    <span class="n">transforms</span><span class="p">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span> <span class="c1"># 이미지를 무작위로 수평 뒤집기 수행! 학습 데이터셋에만 적용!
</span>                    <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                    <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                  <span class="p">])),</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span>
  <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s">'./.data'</span><span class="p">,</span>
                  <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                  <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                  <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
                    <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                    <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                  <span class="p">])),</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>
<p>이미지를 뒤집는 것만으로도 학습 데이터 수가 2배 늘었다!</p>

<h2 id="6-3-드롭아웃">6-3. 드롭아웃</h2>
<p>드롭아웃은 학습 진행 과정에서 신경망의 일부를 사용하지 않는 방법이다. 만약 50% 드롭아웃을 한다면, 학습 단계마다 절반의 뉴런만 사용하도록 한다. 그리고 검증과 테스트 단계에서는 모든 뉴런을 사용한다. 학습에서 배재된 뉴런 외에 다른 뉴런들에 가중치를 분산시키고, 개별 뉴런이 특징에 고정되는 현상을 방지하는 기능을 한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">dropout_p</span> <span class="o">=</span> <span class="n">dropout_p</span>  <span class="c1"># 드롭아웃 확률 기본값 0.2로 설정! 학습시 20% 뉴런을 사용하지 않겠다는 의미
</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="c1"># 가중치가 없으므로, torch.nn.functional 패키지에서 가져와서 사용! nn.Dropout 클래스 사용도 가능!
</span>    <span class="c1"># self.training은 몇 가지 내부 변수를 자동으로 적용해주는 모듈이다.
</span>    <span class="c1"># model.train()과 model.eval()로 학습모드냐, 평가모드냐에 따라 모델 내부의 self.training 변수값이 True 또는 False로 바뀐다!
</span>    <span class="c1"># fc1 지나면서 1번 수행
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">training</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">dropout_p</span><span class="p">)</span> 
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="c1"># fc2 지나면서 또 다시 1번 수행
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">training</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">dropout_p</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</code></pre></div></div>

<p>이제 나머지 코드도 작성해서 결과를 확인해보자!</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
  <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
      <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">target</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
      <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">):</span>
  <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
  <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
      <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">target</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
      <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
      <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="p">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="p">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">)).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
  
  <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>
  <span class="n">test_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
  <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
  <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="s">'[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [1] Test Loss: 0.5419, Accuracy: 83.04%
       [2] Test Loss: 0.4139, Accuracy: 87.15%
       [3] Test Loss: 0.3397, Accuracy: 89.55%
       [4] Test Loss: 0.2877, Accuracy: 91.15%
       [5] Test Loss: 0.2485, Accuracy: 92.31%
       [6] Test Loss: 0.2207, Accuracy: 93.18%
       [7] Test Loss: 0.2026, Accuracy: 93.71%
       [8] Test Loss: 0.1851, Accuracy: 94.25%
       [9] Test Loss: 0.1743, Accuracy: 94.55%
       [10] Test Loss: 0.1636, Accuracy: 94.83%
       [11] Test Loss: 0.1539, Accuracy: 95.21%
       [12] Test Loss: 0.1481, Accuracy: 95.39%
       [13] Test Loss: 0.1409, Accuracy: 95.57%
       [14] Test Loss: 0.1377, Accuracy: 95.70%
       [15] Test Loss: 0.1325, Accuracy: 95.87%
       [16] Test Loss: 0.1317, Accuracy: 95.87%
       [17] Test Loss: 0.1267, Accuracy: 96.01%
       [18] Test Loss: 0.1245, Accuracy: 95.95%
       [19] Test Loss: 0.1207, Accuracy: 96.07%
       [20] Test Loss: 0.1190, Accuracy: 96.16%
       [21] Test Loss: 0.1147, Accuracy: 96.37%
       [22] Test Loss: 0.1126, Accuracy: 96.32%
       [23] Test Loss: 0.1101, Accuracy: 96.44%
       [24] Test Loss: 0.1097, Accuracy: 96.44%
       [25] Test Loss: 0.1070, Accuracy: 96.41%
       [26] Test Loss: 0.1037, Accuracy: 96.63%
       [27] Test Loss: 0.1002, Accuracy: 96.73%
       [28] Test Loss: 0.1031, Accuracy: 96.72%
       [29] Test Loss: 0.1020, Accuracy: 96.69%
       [30] Test Loss: 0.0989, Accuracy: 96.85%
       [31] Test Loss: 0.0996, Accuracy: 96.81%
       [32] Test Loss: 0.0976, Accuracy: 96.88%
       [33] Test Loss: 0.0953, Accuracy: 96.92%
       [34] Test Loss: 0.0960, Accuracy: 96.96%
       [35] Test Loss: 0.0931, Accuracy: 97.04%
       [36] Test Loss: 0.0923, Accuracy: 97.08%
       [37] Test Loss: 0.0952, Accuracy: 97.08%
       [38] Test Loss: 0.0937, Accuracy: 97.14%
       [39] Test Loss: 0.0914, Accuracy: 97.20%
       [40] Test Loss: 0.0903, Accuracy: 97.15%
       [41] Test Loss: 0.0904, Accuracy: 97.22%
       [42] Test Loss: 0.0882, Accuracy: 97.15%
       [43] Test Loss: 0.0902, Accuracy: 97.01%
       [44] Test Loss: 0.0870, Accuracy: 97.16%
       [45] Test Loss: 0.0879, Accuracy: 97.16%
       [46] Test Loss: 0.0864, Accuracy: 97.26%
       [47] Test Loss: 0.0856, Accuracy: 97.36%
       [48] Test Loss: 0.0856, Accuracy: 97.26%
       [49] Test Loss: 0.0866, Accuracy: 97.23%
       [50] Test Loss: 0.0858, Accuracy: 97.29%    
</code></pre></div></div>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#deep-learning" class="page__taxonomy-item p-category" rel="tag">deep learning</a><span class="sep">, </span>
    
      <a href="/tags/#dnn" class="page__taxonomy-item p-category" rel="tag">DNN</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item p-category" rel="tag">pytorch</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#deeplearningpyt" class="page__taxonomy-item p-category" rel="tag">deeplearningpyt</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-02-06T00:00:00+09:00">February 6, 2022</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/deeplearningpyt/deeplearningpyt5/" class="pagination--pager" title="[Deeplearning(pytorch)] 5. 인공 신경망으로 패션 아이템 분류하기
">Previous</a>
    
    
      <a href="/deeplearningpyt/deeplearningpyt7/" class="pagination--pager" title="[Deeplearning(pytorch)] 7. CNN 기초와 모델 구현
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/comm/comm22/" rel="permalink">[네트워크 초급] 22. 라우터의 구조
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-05-24T00:00:00+09:00">May 24, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “모두의 네트워크” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/comm/comm21/" rel="permalink">[네트워크 초급] 21. 서브넷의 구조
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-05-18T00:00:00+09:00">May 18, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “모두의 네트워크” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/comm/comm20/" rel="permalink">[네트워크 초급] 20. 네트워크 주소와 브로드캐스트 주소의 구조
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-05-18T00:00:00+09:00">May 18, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “모두의 네트워크” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/comm/comm19/" rel="permalink">[네트워크 초급] 19. IP 주소의 클래스 구조
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-05-17T00:00:00+09:00">May 17, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “모두의 네트워크” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
          <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-gitlab" aria-hidden="true"></i> GitLab</a></li>
        
      
        
      
        
          <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Kiwon Yang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'kiwon107/kiwon107.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  





  </body>
</html>
