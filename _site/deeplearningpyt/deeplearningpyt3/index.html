<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[Deeplearning(pytorch)] 3. 신경망 모델 구현하기 - Wonny’s DevLog</title>
<meta name="description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">


  <meta name="author" content="K.W. Yang">
  
  <meta property="article:author" content="K.W. Yang">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Wonny's DevLog">
<meta property="og:title" content="[Deeplearning(pytorch)] 3. 신경망 모델 구현하기">
<meta property="og:url" content="http://localhost:4000/deeplearningpyt/deeplearningpyt3/">


  <meta property="og:description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">







  <meta property="article:published_time" content="2022-01-29T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/deeplearningpyt/deeplearningpyt3/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Kiwon Yang",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Wonny's DevLog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
        equationNumbers: {
        autoNumber: "AMS"
        }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
    }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo.png" alt="Wonny's DevLog"></a>
        
        <a class="site-title" href="/">
          Wonny's DevLog
          <span class="site-subtitle">Version 1.0</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/profile.jpg" alt="K.W. Yang" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">K.W. Yang</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>AI Researcher &amp; Developer</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:p2881p@naver.com" rel="me" class="u-email">
            <meta itemprop="email" content="p2881p@naver.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">AI</span>
        

        
        <ul>
          
          
            <li><a href="/machinelearning/">머신러닝(사이킷런) (14)</a></li>
          
          
            <li><a href="/deeplearningpyt/">딥러닝(파이토치) (8)</a></li>
          
          
            <li><a href="/deeplearningtens/">딥러닝(텐서플로우) (6)</a></li>
          
          
            <li><a href="/tensortextbook/">딥러닝 텐서플로 교과서 (1)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Language</span>
        

        
        <ul>
          
          
            <li><a href="/pythonmd/">파이썬 중급 (26)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">CS Theory</span>
        

        
        <ul>
          
          
            <li><a href="/os/">운영체제 ()</a></li>
          
          
            <li><a href="/algopy/">자료구조와 알고리즘(파이썬) (1)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Mathematics</span>
        

        
        <ul>
          
          
            <li><a href="/prob/">확률과 통계 (2)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <a href="/paper/"><span class="nav__sub-title">논문</span></a>
        

        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Deeplearning(pytorch)] 3. 신경망 모델 구현하기">
    <meta itemprop="description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">
    <meta itemprop="datePublished" content="2022-01-29T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/deeplearningpyt/deeplearningpyt3/" class="u-url" itemprop="url">[Deeplearning(pytorch)] 3. 신경망 모델 구현하기
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-01-29T00:00:00+09:00">January 29, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          5 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#3-1-인공-신겸망ann">3-1. 인공 신겸망(ANN)</a></li><li><a href="#3-2-간단한-분류-모델-구현하기">3-2. 간단한 분류 모델 구현하기</a></li></ul>

            </nav>
          </aside>
        
        <p>본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="3-1-인공-신겸망ann">3-1. 인공 신겸망(ANN)</h2>
<p>인공 신경망(Artificial Neural Network)는 인간의 뇌 혹은 신경계의 작동 방식에서 영감을 받았다.<br /></p>
<ul>
  <li>입력층: 인공 신경망에서 자극을 입력받는 감각기관에 해당하는 부분</li>
  <li>은닉층: 입력층을 거친 자극을 처리해 다음 은닉층(인접한 신경세포)로 전달하는 부분. 이렇게 여러 은닉층을 거쳐 자극이 처리되다 보면, 자극에 따라 다양한 반응을 보이게 됨.</li>
  <li>출력층: 은닉층을 거쳐 처리된 자극이 거치는 마지막 뉴런.</li>
  <li>노드: 각 층에 존재하는 한 단위의 인공뉴런</li>
</ul>

<p>하나의 생물학적 신경세포는 인접한 신경세포로 자극을 전달하기 전, 입력받은 자극에 여러 화학적 처리를 가함. 이와 비슷하게 인공 신경망도 가중치와 편향을 이용하여 데이터를 처리한다.</p>
<ul>
  <li>가중치: 입력 신호가 출력에 주는 영향을 계산하는 매개변수</li>
  <li>편향: 노드가 얼마나 데이터에 민감한지 알려주는 매개변수</li>
  <li>활성화 함수: 입력에 적절한 처리를 하여 출력 신호로 변환하는 함수. 입력 신호의 합이 활성화를 일으키는지 아닌지를 정의. 즉 다음 뉴런으로 자극(데이터)을 어느정도 활성화시켜 전달할지를 알려줌!</li>
</ul>

<p>각 층마다 가중치 곱과 활성화 함수를 거치고, 이렇게 층 간 자극 처리와 전달 과정을 몇 겹 걸쳐 반복한 후 마지막 출력층에서 결과값을 만들어내는 것이 인공 신경망의 기본적인 작동 원리이다.<br />
그 다음, 인공 신경망의 출력층이 낸 결과값과 정답을 비교하여 오차를 계산한다. 이 오차를 기반으로 경사하강법을 활용해 출력층의 가중치부터 입력층의 가중치까지 모두 변경해준다. 이렇게 전체 층의 가중치를 뒤에서부터 차례대로 조정하고 최적화하는 알고리즘이 바로 <strong>역전파 알고리즘</strong>이다.</p>

<h2 id="3-2-간단한-분류-모델-구현하기">3-2. 간단한 분류 모델 구현하기</h2>
<p>지도학습 중 분류를 하는 간단한 ANN을 만들어보자. 넘파이, 사이킷런, 맷플롯립을 임포트 할 것이다.</p>
<ul>
  <li>넘파이: 유명한 수치해석용 라이브러리. 행렬과 벡터 연산에 유용. 파이토치도 이 넘파이를 활용하여 개발됨.</li>
  <li>사이킷런: 파이썬의 대표적인 머신러닝 라이브러리. 딥러닝을 제외한 머신러닝은 거의 이 라이브러리 쓴다 봐도 무방.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
</code></pre></div></div>

<p>먼저 신경망 학습과 평가에 사용할 데이터셋을 만든다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_dim</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># 2차원 벡터 형태로 4개의 클러스터 갖는 데이터 만듬. 각 데이터는 0, 1, 2, 3으로 인덱싱 됨.
</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># 0번과 1번 레이블 갖는 데이터는 전부 0번, 2번과 3번 레이블 갖는 데이터는 전부 1번
</span><span class="k">def</span> <span class="nf">label_map</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="n">from_</span><span class="p">,</span> <span class="n">to_</span><span class="p">):</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">y_</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">from_</span><span class="p">:</span>
    <span class="n">y</span><span class="p">[</span><span class="n">y_</span> <span class="o">==</span> <span class="n">f</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_</span>
  <span class="k">return</span> <span class="n">y</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">label_map</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">label_map</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">label_map</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">label_map</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>데이터가 잘 만들어졌는지 시각화 해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">vis_data</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s">'r'</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">x_</span><span class="p">,</span> <span class="n">y_</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">y_</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">'*'</span><span class="p">,</span> <span class="n">marketfacecolor</span><span class="o">=</span><span class="s">'none'</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">+</span><span class="s">'o'</span> <span class="k">if</span> <span class="n">y_</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="n">c</span><span class="o">+</span><span class="s">'+'</span><span class="p">)</span>
  
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">vis_data</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningpyt/3-1.png" alt="그림 3-1. 코드 결과" /></p>
<p>그림 3-1. 코드 결과</p>

<p>데이터가 잘 생성된 것으로 보인다. 이제 넘파이 벡터 형식의 데이터들을 파이토치 텐서로 바꿔주자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<p>이제 신경망 모델을 만들자. 파이토치에서 신경망은 신경망 모듈(torch.nn.Module)을 상속받는 파이썬 클래스로 정의한다. nn.Module을 상속받으면 파이토치 프레임워크에 있는 각종 도구를 쉽게 적용할 수 있다.<br />
신경망의 구조와 동작을 정의하는 생성자를 모델 클래스에 먼저 정의한다. <code class="language-plaintext highlighter-rouge">NeuralNet</code>클래스의 객체를 만들 때 <code class="language-plaintext highlighter-rouge">input_size</code>와 <code class="language-plaintext highlighter-rouge">hidden_size</code>를 입력받도록 정의한다. <code class="language-plaintext highlighter-rouge">input_size</code>는 신경망에 입력되는 데이터의 차원이다.<br />
다음 입력된 데이터가 인공 신경망 통과하면서 거치는 연산들을 정의한다. <code class="language-plaintext highlighter-rouge">torch.nn.Linear()</code>함수는 행렬곱과 편향을 포함한 연산을 지원하는 객체를 반환한다. <code class="language-plaintext highlighter-rouge">linear_1</code>과 <code class="language-plaintext highlighter-rouge">linear_2</code>객체는 나중에 함수로 쓰일 수 있다. <code class="language-plaintext highlighter-rouge">relu()</code>와 <code class="language-plaintext highlighter-rouge">sigmoid()</code>는 각 단계에서 수행할 활성화 함수이다.<br />
마지막으로 생성자 <code class="language-plaintext highlighter-rouge">__init__()</code>에서 정의한 동작들을 차례대로 실행하는 <code class="language-plaintext highlighter-rouge">forward()</code> 함수를 구현한다. <code class="language-plaintext highlighter-rouge">linear_1</code>은 입력 데이터에 <code class="language-plaintext highlighter-rouge">[input_size, hidden_size]</code> 크기의 가중치를 행렬곱하고 편향을 더하여 <code class="language-plaintext highlighter-rouge">[1, hidden_size]</code>꼴의 텐서를 반환한다. 이 텐서에 <code class="language-plaintext highlighter-rouge">relu()</code>함수를 적용하여 0보다 작으면 0을, 0보다 크면 입력값을 그대로 출력하도록 한다. 그 다음 다시 <code class="language-plaintext highlighter-rouge">linear_2</code> 함수를 거쳐 <code class="language-plaintext highlighter-rouge">[1,1]</code> 꼴의 텐서를 반환한다. 이 텐서를 <code class="language-plaintext highlighter-rouge">sigmoid()</code> 거쳐 0과 1사이의 확률값으로 변환되도록 한다. 0에 가까우면 클래스 0, 1에 가까우면 클래스 1이 반환될 것이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NeuralNet</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    
    <span class="bp">self</span><span class="p">.</span><span class="n">linear_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">input_size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">linear_2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sigmoid</span><span class="p">()</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
    <span class="n">linear1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear_1</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span> <span class="c1"># __call__ 함수로 구현하면 해당 객체 호출하여 데이터 입력시 출력값 리턴 가능하다!
</span>    <span class="n">relu</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">linear1</span><span class="p">)</span>
    <span class="n">linear2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear_2</span><span class="p">(</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">linear2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>
</code></pre></div></div>

<p>이제 신경망 객체 생성 후 학습에 필요한 여러 변수와 알고리즘을 정의한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNet</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.03</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</code></pre></div></div>

<p>criterion은 여러 오차 함수 중 어떤 함수를 쓸 것인지에 대한 변수로, 여기서는 이진 교차 엔트로피인 <code class="language-plaintext highlighter-rouge">BCELoss()</code> 함수를 사용한다. 에폭은 전체 학습 데이터를 총 몇 번 모델에 입력할지 결정하는 변수이다. 에폭은 너무 작게 설정하면 모델이 충분히 학습되지 않을 수 있으며, 크게 설정하면 학습이 오래걸린다. 학습에 사용할 최적화 알고리즘은 확률적 경사하강법(SGD)를 선택할 것이다. <code class="language-plaintext highlighter-rouge">optimizer</code>는 <code class="language-plaintext highlighter-rouge">step()</code> 함수를 부를 때 마다 가중치를 학습률만큼 갱신한다. 그래서 <code class="language-plaintext highlighter-rouge">moel.parameter()</code> 함수로 모델 내부의 가중치를 <code class="language-plaintext highlighter-rouge">SGD()</code> 함수에 입력하고 학습률도 <code class="language-plaintext highlighter-rouge">SGD()</code> 함수에 입력했다.<br /></p>

<p>이제 아직 학습하지 않은 모델의 성능을 보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">test_loss_before</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">).</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">y_test</span><span class="p">)</span>  <span class="c1"># 모델의 결과값과 레이블값의 차원을 맞추기 위해 squeeze() 함수 사용
</span><span class="k">print</span><span class="p">(</span><span class="s">'Before Training, test loss is {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_loss_before</span><span class="p">.</span><span class="n">item</span><span class="p">()))</span>  <span class="c1"># 텐서 속 숫자를 스칼라 값으로 변환하기 위해 item() 함수 사용
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Before Training, test loss is 0.645291805267334 # 100번 찍어 64번 틀린다는 뜻
</code></pre></div></div>

<p>이제 신경망을 학습시켜보자. 모델에 <code class="language-plaintext highlighter-rouge">train()</code> 함수를 호출하여 학습 모드로 바꿔준다. 에폭마다 새로운 경사값을 계산할 것이므로, <code class="language-plaintext highlighter-rouge">zero_grad()</code> 함수 사용하여 경사값을 0으로 설정한다. 그리고 앞서 생성한 모델에 학습데이터를 입력하여 결과값을 계산한다. 이어 결과값의 차원을 학습 레이블의 차원과 같게 만들고 오차를 계산한다. 100 에폭마다 오차를 출력하여 학습 잘 되는지 확인할 것이다. 마지막으로 오차 함수를 가중치로 미분하여 오차가 최소가 되는 방향을 구하고, 그 방향으로 모델을 학습률만큼 이동시킨다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
  <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
  <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
  <span class="n">train_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
  <span class="n">train_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">train_output</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">y_train</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Train loss at {} is {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">.</span><span class="n">item</span><span class="p">()))</span>
  <span class="n">train_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
  <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Train loss at 0 is 0.7493579983711243
       Train loss at 100 is 0.6670505404472351
       Train loss at 200 is 0.6009105443954468
       Train loss at 300 is 0.5226348042488098
       Train loss at 400 is 0.4344537854194641
       Train loss at 500 is 0.34321680665016174
       Train loss at 600 is 0.2647372782230377
       Train loss at 700 is 0.20638075470924377
       Train loss at 800 is 0.1649305522441864
       Train loss at 900 is 0.13516339659690857
       Train loss at 1000 is 0.11338607966899872
       Train loss at 1100 is 0.09709872305393219
       Train loss at 1200 is 0.08457082509994507
       Train loss at 1300 is 0.07471741735935211
       Train loss at 1400 is 0.06681334227323532
       Train loss at 1500 is 0.060360174626111984
       Train loss at 1600 is 0.05501692369580269
       Train loss at 1700 is 0.0505140945315361
       Train loss at 1800 is 0.046674009412527084
       Train loss at 1900 is 0.04336244985461235
</code></pre></div></div>

<p>훈련을 시킬수록 오차가 점점 줄어들었다. 신경망 학습이 끝났으니, 이제 학습된 신경망의 성능을 시험해보자. 모델을 평가 모드로 바꾸고 예측값과 정답간 오차를 구한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">test_loss_before</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">)),</span> <span class="n">y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'After Training, test loss is {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_loss_before</span><span class="p">.</span><span class="n">item</span><span class="p">()))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) After Training, test loss is 0.051639605313539505
</code></pre></div></div>

<p>학습을 시키니 성능이 훨신 개선되었다!</p>

<p>이제 학습된 모델을 <code class="language-plaintext highlighter-rouge">state_dict()</code> 함수 형태로 바꾸고 .pt 파일로 저장하자. <code class="language-plaintext highlighter-rouge">state_dict()</code> 함수는 모댈 내 가중치들이 딕셔너리 형태로 표현된 데이터이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s">'./model.pt'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'state_dict format of the model: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">()))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) state_dict format of the model: OrderedDict([('linear_1.weight', tensor([[ 1.6538, -1.5809],
       [-0.8564,  0.9028],
       [-1.2493,  1.3215],
       [-0.7172,  0.5184],
       [-1.5437,  1.6288]])), ('linear_1.bias', tensor([-0.3444, -0.0939, -0.2914,  1.8187, -0.3649])), ('linear_2.weight', tensor([[ 2.2818,  0.9448,  1.6297, -1.8723,  2.0588]])), ('linear_2.bias', tensor([-1.0846]))])
</code></pre></div></div>

<p>만약 이 학습된 모델을 다시 사용하고 싶다면, 다음 코드처럼 이 파일을 읽어들여 새로운 신경망 객체에 해당 모델의 가중치를 바로 적용할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_model</span> <span class="o">=</span> <span class="n">NeuralNet</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">new_model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'./model.pt'</span><span class="p">))</span>
<span class="n">new_model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'벡터 [-1, 1] 레이블 1을 가질 확률: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">new_model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])).</span><span class="n">item</span><span class="p">()))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 벡터 [-1, 1] 레이블 1을 가질 확률: 0.9861477613449097
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#ann" class="page__taxonomy-item p-category" rel="tag">ANN</a><span class="sep">, </span>
    
      <a href="/tags/#deep-learning" class="page__taxonomy-item p-category" rel="tag">deep learning</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item p-category" rel="tag">pytorch</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#deeplearningpyt" class="page__taxonomy-item p-category" rel="tag">deeplearningpyt</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-01-29T00:00:00+09:00">January 29, 2022</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/deeplearningpyt/deeplearningpyt2/" class="pagination--pager" title="[Deeplearning(pytorch)] 2. 경사하강법으로 이미지 복원하기
">Previous</a>
    
    
      <a href="/machinelearning/machinelearning3/" class="pagination--pager" title="[Machine learning] 3. 데이터 전처리
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/tensortextbook/machinelearning16/" rel="permalink">[Machine learning] 2. 지도 학습
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-02-28T00:00:00+09:00">February 28, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “딥러닝 텐서플로 교과서” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningtens/deeplearningtens6/" rel="permalink">[Deeplearning(Tensorflow)] 6. 합성곱 신경망의 시각화
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-02-28T00:00:00+09:00">February 28, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          5 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningtens/deeplearningtens5/" rel="permalink">[Deeplearning(Tensorflow)] 5. 합성곱 신경망을 사용한 이미지 분류
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-02-27T00:00:00+09:00">February 27, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningtens/deeplearningtens4/" rel="permalink">[Deeplearning(Tensorflow)] 4. 합성곱 신경망의 구성 요소
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-02-27T00:00:00+09:00">February 27, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
          <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-gitlab" aria-hidden="true"></i> GitLab</a></li>
        
      
        
      
        
          <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Kiwon Yang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'kiwon107/kiwon107.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  





  </body>
</html>
