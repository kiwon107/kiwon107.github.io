<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[Deeplearning(pytorch)] 11. RNN 개요와 영화 리뷰 감정 분석 - Wonny’s DevLog</title>
<meta name="description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">


  <meta name="author" content="K.W. Yang">
  
  <meta property="article:author" content="K.W. Yang">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Wonny's DevLog">
<meta property="og:title" content="[Deeplearning(pytorch)] 11. RNN 개요와 영화 리뷰 감정 분석">
<meta property="og:url" content="http://localhost:4000/deeplearningpyt/deeplearningpyt11/">


  <meta property="og:description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다. 잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">







  <meta property="article:published_time" content="2022-03-11T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/deeplearningpyt/deeplearningpyt11/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Kiwon Yang",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Wonny's DevLog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
        equationNumbers: {
        autoNumber: "AMS"
        }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
    }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo.png" alt="Wonny's DevLog"></a>
        
        <a class="site-title" href="/">
          Wonny's DevLog
          <span class="site-subtitle">Version 1.0</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/profile.jpg" alt="K.W. Yang" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">K.W. Yang</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>AI Researcher &amp; Developer</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">South Korea</span>
        </li>
      

      
        
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instagram</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:p2881p@naver.com" rel="me" class="u-email">
            <meta itemprop="email" content="p2881p@naver.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">AI</span>
        

        
        <ul>
          
          
            <li><a href="/machinelearning/">머신러닝(사이킷런) (14)</a></li>
          
          
            <li><a href="/deeplearningpyt/">딥러닝(파이토치) (16)</a></li>
          
          
            <li><a href="/deeplearningtens/">딥러닝(텐서플로우) (9)</a></li>
          
          
            <li><a href="/tensortextbook/">딥러닝 텐서플로 교과서 (1)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Language</span>
        

        
        <ul>
          
          
            <li><a href="/pythonmd/">파이썬 중급 (26)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">CS Theory</span>
        

        
        <ul>
          
          
            <li><a href="/os/">운영체제 ()</a></li>
          
          
            <li><a href="/algopy/">자료구조와 알고리즘(파이썬) (1)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Mathematics</span>
        

        
        <ul>
          
          
            <li><a href="/prob/">확률과 통계 (2)</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <a href="/paper/"><span class="nav__sub-title">논문</span></a>
        

        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[Deeplearning(pytorch)] 11. RNN 개요와 영화 리뷰 감정 분석">
    <meta itemprop="description" content="본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.">
    <meta itemprop="datePublished" content="2022-03-11T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/deeplearningpyt/deeplearningpyt11/" class="u-url" itemprop="url">[Deeplearning(pytorch)] 11. RNN 개요와 영화 리뷰 감정 분석
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-11T00:00:00+09:00">March 11, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#11-1-rnn-개요">11-1. RNN 개요</a></li><li><a href="#11-2-토크나이징과-워드-임베딩">11-2. 토크나이징과 워드 임베딩</a></li><li><a href="#11-3-영화-리뷰-감정-분석">11-3. 영화 리뷰 감정 분석</a></li></ul>

            </nav>
          </aside>
        
        <p>본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="11-1-rnn-개요">11-1. RNN 개요</h2>
<p>지금까지 배운 신경망은 연달아 있는 데이터의 순서와 상호작용을 인식하여 전체 상황을 이해하는 능력을 가지고 있지 않았다. 즉, 시간에 대한 개념이 없는 데이터와 그에 따른 신경망을 다룬 것이다. 앞서 이미지와 같은 정적인 데이터를 인지하는 모델들을 다뤘지만, 현실에서 접하는 거의 모든 경험은 순차적이다. 이번에는 <strong>순처적 데이터(Sequential data)</strong> 혹은 <strong>시계열 데이터(Time series data)</strong> 정보를 받아 전체 내용을 학습하는 <strong>RNN(Recurrent Neural Network)</strong> 를 다뤄본다.</p>

<p>RNN은 정해지지 않은 길이의 배열을 읽고 설명하는 신경망이다. RNN의 출력은 순차적 데이터의 흐름을 모두 내포한다. 시계열 데이터의 정보를 하나씩 입력받을 때마다 지금까지 입력된 벡터들을 종합해 <strong>은닉 벡터(Hidden vector)</strong>를 만든다. 첫 번째 학습 데이터 벡터 입력1을 입력받은 RNN은 은닉벡터1을 생성한다. 입력1에 이어 입력2까지 RNN에 입력되면 입력1과 입력2를 압축한 은닉벡터2가 만들어진다. 이런식으로 마지막 입력K 까지 입력받은 RNN은 이들을 모두 압축하여 은닉벡터K를 만들어낸다. 마지막 은닉벡터K는 배열 속 모든 벡터들의 내용을 압축한 벡터라고 할 수 있다.</p>

<p>RNN 계열 신경망들은 텍스트나 자연어를 처리하고 학습하는데 주로 사용된다. 현재는 <strong>LSTM(Long short term memory)</strong>, <strong>GRU(Gated recurrent unit)</strong> 등 응용 RNN이 개발되어 언어 모델링, 텍스트 감정 분석, 기계 번역 등 분야에 활발하게 이용되고 있다.</p>

<p>RNN을 이용한 신경망 형태는 크게 4가지가 있다. <strong>일대일(one to one)</strong>은 일반적으로 그동안 보았던 신경망이나 CNN과 같다. <strong>일대다(one to many)</strong>는 이미지를 보고 이미지 안의 상황을 글로 설명하는 등의 신경망이다.  <strong>다대일(many to one)</strong>은 감정 분석 같이 순차적인 데이터를 보고 값 하나를 내는 경우이다. <strong>다대다(many to many)</strong>는 2가지 유형이 있는데, 챗봇과 기계 번역 같이 순차적인 데이터를 보고 순차적인 데이터를 출력하는 유형과 비디오 분류 같이 매 프레임을 레이블링할 때 사용되는 유형이 있다.</p>

<h2 id="11-2-토크나이징과-워드-임베딩">11-2. 토크나이징과 워드 임베딩</h2>
<p>이번 시간에는 자연어 텍스트 데이터를 다뤄볼 것이다. 이러한 데이터를 인공 신경망에 입력시키려면 전처리 과정을 거쳐 데이터를 숫자로 나타내야 한다. 전처리를 위해 가장 먼저 해야할 작업은 텍스트 문장을 언어의 최소 단위인 <strong>토큰(Token)</strong>으로 나누는 것이다. <code class="language-plaintext highlighter-rouge">split()</code> 함수를 사용하여 단어 단위로 <strong>토크나이징(Tokenizing)</strong> 해도 큰 문제 없으며, <code class="language-plaintext highlighter-rouge">SpaCy</code> 같은 오픈소스 라이브러리를 사용하는 것도 좋다.<br />
그 다음 문장 속 모든 토큰을 각각 벡터로 나타내주어야 한다. 벡터로 나타내기 위해서 데이터셋의 모든 단어 수만큼 벡터를 담는 <strong>사전(Dictionary)</strong>을 정의해야 한다. 만약 ‘Quick brown fox jumps over the lazy dog.’ 이라는 문장이 있다면, 다음과 같이 사전에 단어 벡터가 총 8개 담기게 된다. <code class="language-plaintext highlighter-rouge">['quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']</code>. ‘brown’ 단어를 벡터로 변환하려면 이 사전에서 ‘brown’에 해당되는 벡터를 가져오면 된다. 이처럼 언어의 최소 단위인 토큰을 벡터 형태로 변환하는 작업을 <strong>워드 임베딩(Word embedding)</strong> 이라고 한다.</p>

<h2 id="11-3-영화-리뷰-감정-분석">11-3. 영화 리뷰 감정 분석</h2>
<p>데이터의 순서 정보를 학습한다는 점에서 RNN은 동영상, 자연어, 주가 등 동적인 데이터를 이용할 때 성능이 극대화된다. 이번에는 IMDB 데이터셋을 활용할 것이다. 이 데이터셋은 영화 리뷰 5만 건으로 이뤄졌다. 각 리뷰는 다수의 영어 문장으로 구성되었으며, 긍정 영화 리뷰는 2, 부정 영화 리뷰는 1로 레이블링 되어있다. 해당 데이터셋을 이용하여 영화 리뷰가 긍정적인지 부정적인지 판단해주는 간단한 분류 모델을 만들어 볼 것이다.<br /></p>

<p>먼저 관련 모듈 임포트, 모델 파라미터 설정, 데이터 생성 및 전처리 단계이다</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 관련 모듈 임포트
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchtext.legacy</span> <span class="kn">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">datasets</span>

<span class="c1"># 모델 파라미터 설정
</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">USE_CUDA</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">USE_CUDA</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>

<span class="c1"># 데이터를 텐서로 변환시 필요한 설정 객체 생성
</span><span class="n">TEXT</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">Field</span><span class="p">(</span><span class="n">sequential</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># sequential: 데이터셋이 순차적인가?, batch_first: 신경망에 입력되는 텐서의 첫 번째 차원값이 batch_size 되도록 설정, lower: 텍스트 데이터 속 모든 영문 알파벳이 소문자가 되도록 설정
</span><span class="n">LABEL</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">Field</span><span class="p">(</span><span class="n">sequential</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 모델에 입력되는 데이터 셋 생성
</span><span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">IMDB</span><span class="p">.</span><span class="n">splits</span><span class="p">(</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">LABEL</span><span class="p">)</span>

<span class="c1"># 워드 임베딩에 필요한 단어 사전(Word vocabulary) 생성
</span><span class="n">TEXT</span><span class="p">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># min_freq: 최소 5번 이상 등장한 단어만을 사전에 담도록 설정, 5번 미만 등장한 단어는 unknown인 'unk'라는 토큰으로 대체
</span><span class="n">LABEL</span><span class="p">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span>

<span class="c1"># 훈련, 검증, 테스트 데이터셋 생성
</span><span class="n">trainset</span><span class="p">,</span> <span class="n">valset</span> <span class="o">=</span> <span class="n">trainset</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">split_ratio</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span> <span class="c1"># 80% 는 훈련셋, 나머지는 검증셋으로 활용
</span><span class="n">train_iter</span><span class="p">,</span> <span class="n">val_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">BucketIterator</span><span class="p">.</span><span class="n">splits</span><span class="p">((</span><span class="n">trainset</span><span class="p">,</span> <span class="n">valset</span><span class="p">,</span> <span class="n">testset</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># 배치 단위의 반복자(Iterator) 생성
</span>
<span class="c1"># 사전 속 데이터들의 개수와 레이블 수 정해주는 변수 생성
</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">TEXT</span><span class="p">.</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">print</span><span class="p">(</span><span class="s">"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d"</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">valset</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">testset</span><span class="p">),</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2
</code></pre></div></div>

<p>그 다음은 모델 설계 단이다.<br />
여기서는 GRU 라는 모델을 사용한다. 왜 RNN은 안쓰고 GRU를 사용하려는 걸까?<br />
RNN은 입력이 길어지면 학습 도중 기울기가 너무 작아지거나 커져서 앞부분에 대한 정보를 정확히 담지 못할 수 있다. 기울기가 학습 도중 폭발적으로 커지는 현상을 <strong>기울기 폭발(Gradient explosion)</strong> 이라 하며, 기울기가 너무 작아지는 현상을 <strong>기울기 소실(Vanishing gradient)</strong>라고 한다. 이를 보완하기 위해 만들어진 대표 모델이 <strong>LSTM(Long-short term memory)</strong>과 <strong>GRU(Gated recurrent unit)</strong>이다. GRU는 시계열 데이터 속 벡터 사이의 정보 전달량을 조절하여 기울기를 적정하게 유지하고 문장 앞부분의 정보가 끝까지 도달할 수 있도록 도와준다.<br />
좀 더 설명을 하자면, GRU에는 시계열 데이터 내 정보 전달량을 조절하는 <strong>업데이트 게이트(Update gate)</strong>와 <strong>리셋 게이트(Reset gate)</strong>가 있다. 업데이트 게이트는 이전 은닉 벡터가 지닌 정보를 새로운 은닉 벡터가 얼마나 유지할지 정해준다. 리셋 게이트는 새로운 입력이 이전 은닉 벡터와 어떻게 조합하는지를 결정한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 모델 설계
</span><span class="k">class</span> <span class="nc">BasicGRU</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_vocab</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BasicGRU</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Bulding Basic GRU model..."</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span> <span class="c1"># 아주 복잡한 모델이 아닌 이상 2 이하로 정의
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_vocab</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span> <span class="c1"># n_vocab: 전체 데이터셋의 모든 단어를 사전 형태로 나타낼 때 그 사전에 등재된 단어 수, embed_dim: 임베딩된 단어 텐서가 지나가는 차원
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span> <span class="c1"># 은닉벡터 차원
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_p</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">h_0</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_init_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="c1"># 첫 번째 은닉 벡터 H0 정의
</span>    <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">gru</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h_0</span><span class="p">)</span> <span class="c1"># (batch_size, 입력 x의 길이, hidden_dim) 모양을 지닌 3d 텐서
</span>    <span class="n">h_t</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="c1"># (batch_size, 1, hidden_dim) 모양의 텐서 추출
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h_t</span><span class="p">)</span>
    <span class="n">logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">out</span><span class="p">(</span><span class="n">h_t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logit</span>

  <span class="k">def</span> <span class="nf">_init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">()).</span><span class="n">data</span> <span class="c1"># 가중치 정보들을 반복자 형태로 반환
</span>    <span class="k">return</span> <span class="n">weight</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">).</span><span class="n">zero_</span><span class="p">()</span> <span class="c1"># 모델의 가중치과 같은 모양인 (n_layers, batch_size, hidden_dim) 모양을 갖춘 텐서로 변환 후 zero_() 함수로 텐서 내 모든 값을 0으로 초기화하여 첫 번째 은닉 벡터의 모든 특성값이 0인 벡터로 설정
</span></code></pre></div></div>

<p>이제 학습 함수와 평가 함수를 구현한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">):</span>
  <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_iter</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">batch</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span> <span class="c1"># batch.label은 1이나 2의 값 가짐
</span>    <span class="n">y</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">sub_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># batch.label이 1 or 2가 아닌 1씩 빼서 0 or 1 값을 갖도록 수정
</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">logit</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_iter</span><span class="p">):</span>
  <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
  <span class="n">corrects</span><span class="p">,</span> <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

  <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_iter</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">batch</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">y</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">sub_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">logit</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">)</span> <span class="c1"># 오차의 합을 구함
</span>    <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># 오차의 합을 total_loss에 더해줌
</span>    <span class="n">corrects</span> <span class="o">+=</span> <span class="p">(</span><span class="n">logit</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">view</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">size</span><span class="p">()).</span><span class="n">data</span> <span class="o">==</span> <span class="n">y</span><span class="p">.</span><span class="n">data</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>
  
  <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_iter</span><span class="p">.</span><span class="n">dataset</span><span class="p">)</span>
  <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">size</span>
  <span class="n">avg_accuracy</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">corrects</span> <span class="o">/</span> <span class="n">size</span>
  <span class="k">return</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="n">avg_accuracy</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">BasicGRU</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">best_val_loss</span> <span class="o">=</span> <span class="bp">None</span>

<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
  <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">)</span>
  <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_iter</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"[이폭: %d] 검증 오차:%5.2f | 검증 정확도: %5.2f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">))</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">best_val_loss</span> <span class="ow">or</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">isdir</span><span class="p">(</span><span class="s">"snapshot"</span><span class="p">):</span>
      <span class="n">os</span><span class="p">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s">"snapshot"</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s">'./snapshot/txtclassification.pt'</span><span class="p">)</span>
    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span>

<span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'./snapshot/txtclassification.pt'</span><span class="p">))</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'테스트 오차: %5.2f | 테스트 정확도: %5.2f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Bulding Basic GRU model...
       [이폭: 1] 검증 오차: 0.70 | 검증 정확도: 49.46
       [이폭: 2] 검증 오차: 0.71 | 검증 정확도: 49.78
       [이폭: 3] 검증 오차: 0.71 | 검증 정확도: 52.72
       ...
       [이폭: 37] 검증 오차: 0.86 | 검증 정확도: 86.28
       [이폭: 38] 검증 오차: 0.88 | 검증 정확도: 86.30
       [이폭: 39] 검증 오차: 0.90 | 검증 정확도: 86.32
       [이폭: 40] 검증 오차: 0.92 | 검증 정확도: 86.28
       테스트 오차:  0.35 | 테스트 정확도: 85.62
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#deep-learning" class="page__taxonomy-item p-category" rel="tag">deep learning</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item p-category" rel="tag">pytorch</a><span class="sep">, </span>
    
      <a href="/tags/#rnn" class="page__taxonomy-item p-category" rel="tag">rnn</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#deeplearningpyt" class="page__taxonomy-item p-category" rel="tag">deeplearningpyt</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2022-03-11T00:00:00+09:00">March 11, 2022</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="/deeplearningpyt/deeplearningpyt10/" class="pagination--pager" title="[Deeplearning(pytorch)] 10. 오토인코더로 망가진 이미지 복원하기
">Previous</a>
    
    
      <a href="/deeplearningpyt/deeplearningpyt12/" class="pagination--pager" title="[Deeplearning(pytorch)] 12. Seq2Seq 기계 번역
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningpyt/deeplearningpyt16/" rel="permalink">[Deeplearning(pytorch)] 16. 주어진 환경과 상호작용하여 학습하는 DQN
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-31T00:00:00+09:00">March 31, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          5 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningpyt/deeplearningpyt15/" rel="permalink">[Deeplearning(pytorch)] 15. cGAN으로 생성 제어하기
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-29T00:00:00+09:00">March 29, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningpyt/deeplearningpyt14/" rel="permalink">[Deeplearning(pytorch)] 14. 경쟁하며 학습하는 GAN
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-28T00:00:00+09:00">March 28, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearningpyt/deeplearningpyt13/" rel="permalink">[Deeplearning(pytorch)] 13. 딥러닝을 해킹하는 적대적 공격
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-03-26T00:00:00+09:00">March 26, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
          <li><a href="https://github.com/kiwon107" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-gitlab" aria-hidden="true"></i> GitLab</a></li>
        
      
        
      
        
          <li><a href="https://instagram.com/k1_won" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Kiwon Yang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'kiwon107/kiwon107.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  





  </body>
</html>
