I"ò?<p>ë³¸ í¬ìŠ¤íŒ…ì€ â€œí­ê·„ë¸Œë¡œì˜ 3ë¶„ ë”¥ëŸ¬ë‹, íŒŒì´í† ì¹˜ë§›â€ ì±… ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
ì˜ëª»ëœ ë‚´ìš©ì´ ìˆì„ ê²½ìš° ì§€ì í•´ ì£¼ì‹œë©´ ê°ì‚¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.</p>

<h2 id="8-1-resnet-ì†Œê°œ">8-1. ResNet ì†Œê°œ</h2>
<p class="align-center">ResNet(Residual Network) ëª¨ë¸ì€ CNNì„ ì‘ìš©í•œ ëª¨ë¸ì´ë‹¤. ì´ë¯¸ì§€ ì²œë§Œ ì¥ì„ í•™ìŠµí•˜ì—¬ 15ë§Œ ì¥ìœ¼ë¡œ ì¸ì‹ë¥ ì„ ê²¨ë£¨ëŠ” ì´ë¯¸ì§€ë„· ëŒ€íšŒì—ì„œ 2015ë…„ë„ ìš°ìŠ¹í•œ ëª¨ë¸. ì‹ ê²½ë§ì„ ê¹Šê²Œ ìŒ“ìœ¼ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë‚˜ë¹ ì§€ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì œì‹œí–ˆë‹¤. ì»¨ë²Œë£¨ì…˜ì¸µì˜ ì¶œë ¥ì— ì „ì˜ ì „ ê³„ì¸µì— ì“°ì˜€ë˜ ì…ë ¥ì„ ë”í•˜ì—¬ íŠ¹ì§•ì´ ìœ ì‹¤ë˜ì§€ ì•Šë„ë¡ í•˜ì˜€ë‹¤(ê·¸ë¦¼ 8-1).
<img src="/assets/images/deeplearningpyt/8-1.png" alt="ê·¸ë¦¼ 8-1. ì½”ë“œ ê²°ê³¼" /></p>
<p>ê·¸ë¦¼ 8-1. ì½”ë“œ ê²°ê³¼</p>

<h2 id="8-2-cifar-10-ë°ì´í„°ì…‹">8-2. CIFAR-10 ë°ì´í„°ì…‹</h2>
<p>CIFAR-10 ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê² ë‹¤. ì´ë¯¸ì§€ë„· ë°ì´í„°ì…‹ì€ ë§¤ìš° ë°©ëŒ€í•˜ê³  ë¼ì´ì„ ìŠ¤ ë¬¸ì œë„ ìˆì–´ í† ì¹˜ë¹„ì „ì— ê¸°ë³¸ ìˆ˜ë¡ë¼ìˆì§€ ì•Šì•„ ì§ì ‘ ë°›ì•„ì•¼ í•œë‹¤. CIFAR-10 ë°ì´í„°ì…‹ì€ 32 x 32 í¬ê¸°ì˜ ì´ë¯¸ì§€ 6ë§Œê°œë¥¼ í¬í•¨í•˜ê³  ìˆê³ , ìë™ì°¨, ìƒˆ, ê³ ì–‘ì´, ì‚¬ìŠ´ ë“± 10ê°€ì§€ ë¶„ë¥˜ê°€ ì¡´ì¬í•œë‹¤. CIFAR-10 ë°ì´í„°ì…‹ì€ ì»¬ëŸ¬ ì´ë¯¸ì§€ë“¤ì„ í¬í•¨í•˜ê³  ìˆëŠ”ë°, ì»¬ëŸ¬ ì´ë¯¸ì§€ í”½ì…€ê°’ì€ ëª‡ ê°€ì§€ ì±„ë„ë“¤ë¡œ êµ¬ì„±ëœë‹¤. ì±„ë„ì€ ì´ë¯¸ì§€ì˜ ìƒ‰ìƒ êµ¬ì„±ìš”ì†Œë¥¼ ê°€ë¦¬í‚¨ë‹¤. ë¹¨ê°•, ì´ˆë¡, íŒŒë‘ ì„¸ ì¢…ë¥˜ì˜ ê´‘ì›ì„ í˜¼í•©í•˜ì—¬ ëª¨ë“  ìƒ‰ì„ í‘œí˜„í•œë‹¤. ì˜¤ëŠ˜ë‚  ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” 24ë¹„íŠ¸ ì»¬ëŸ¬ ì´ë¯¸ì§€ëŠ” R, G, B ê°ê°ì— 8ë¹„íŠ¸ì”© ìƒ‰ìƒê°’ì„ ê°€ì§€ëŠ” 3ê°€ì§€ ì±„ë„ì„ ì‚¬ìš©í•œë‹¤.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">models</span>

<span class="n">USE_CUDA</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">USE_CUDA</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>

<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">BATCH_SIZE</span> <span class="o">-</span> <span class="mi">128</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="p">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s">'./.data'</span><span class="p">,</span>
                  <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                  <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                  <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
                  <span class="n">transforms</span><span class="p">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="n">transforms</span><span class="p">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
                  <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                  <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
                                       <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="p">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s">'./.data'</span><span class="p">,</span>
                  <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                  <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
                    <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                    <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
                                         <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))]))</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="8-3-cnnì„-ê¹Šê²Œ-ìŒ“ëŠ”-ë°©ë²•">8-3. CNNì„ ê¹Šê²Œ ìŒ“ëŠ” ë°©ë²•</h2>
<p class="align-center">ì¸ê³µ ì‹ ê²½ë§ì„ ì—¬ëŸ¬ ê°œ ê²¹ì¹œë‹¤ê³  í•™ìŠµ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ì§„ ì•ŠëŠ”ë‹¤. ì—¬ëŸ¬ ë‹¨ê³„ ì‹ ê²½ë§ì„ ê±°ì¹˜ë©° ìµœì´ˆ ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ë³´ê°€ ì†Œì‹¤ë˜ê¸° ë•Œë¬¸ì´ë‹¤.<br />
ResNetì˜ í•µì‹¬ì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‘ì€ ë¸”ë¡ì¸ Residual ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ì—ˆë‹¤ëŠ” ê²ƒì´ë‹¤.
<img src="/assets/images/deeplearningpyt/8-2.png" alt="ê·¸ë¦¼ 8-2. ì½”ë“œ ê²°ê³¼" /></p>
<p>ê·¸ë¦¼ 8-2. ì½”ë“œ ê²°ê³¼</p>

<p>Rasidual ë¸”ë¡ì˜ ì¶œë ¥ì— ì…ë ¥ì´ì—ˆë˜ xë¥¼ ë”í•˜ì—¬ ëª¨ë¸ì„ í›¨ì”¬ ê¹Šê²Œ ì„¤ê³„í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. ì¦‰, ì…ë ¥ê³¼ ì¶œë ¥ì˜ ê´€ê³„ë¥¼ ë°”ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒë³´ë‹¤, ì…ë ¥ê³¼ ì¶œë ¥ì˜ ì°¨ì´ë¥¼ ë”°ë¡œ í•™ìŠµí•˜ëŠ”ê²Œ ì„±ëŠ¥ì´ ì¢‹ë‹¤ëŠ” ê²ƒì´ë‹¤.<br />
ì‹ ê²½ë§ì„ ê¹Šê²Œ í• ìˆ˜ë¡ ì¢‹ì€ ì´ìœ ëŠ” ë¬¸ì œë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì´ ì¢‹ì•„ì§€ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ê³„ì¸µì´ ê¹Šì–´ì§ì— ë”°ë¼ ì‹ í˜¸ì˜ ê°•ë„ê°€ ê°ì†Œí•˜ê²Œ ëœë‹¤. ResNetì€ ì…ë ¥ ë°ì´í„°ë¥¼ ëª‡ ê³„ì¸µì”© ê±´ë„ˆë›°ì–´ ì¶œë ¥ì— ë”í•¨ìœ¼ë¡œì¨ ì´ í˜„ìƒì„ ì™„í™”í•´ì¤€ë‹¤.<br />
Residual ë¸”ë¡ì„ BasicBlock ì´ë¼ëŠ” ìƒˆë¡œìš´ íŒŒì´í† ì¹˜ ëª¨ë“ˆë¡œ ì •ì˜í•´ì„œ ì‚¬ìš©í•´ë³´ì. ì°¸ê³ ë¡œ BasicBlock ì½”ë“œì—ëŠ” <code class="language-plaintext highlighter-rouge">nn.BatchNorm2d</code>ë¼ëŠ” ë…€ì„ì´ ìˆë‹¤. <strong>ë°°ì¹˜ ì •ê·œí™”(Batch Normalization)</strong>ì„ ìˆ˜í–‰í•˜ëŠ” ê³„ì¸µì¸ë°, í•™ìŠµ ì¤‘ ê° ê³„ì¸µì— ë“¤ì–´ê°€ëŠ” ì…ë ¥ì„ í‰ê· ê³¼ ë¶„ì‚°ìœ¼ë¡œ ì •ê·œí™”í•˜ì—¬, í•™ìŠµë¥ ì„ ë†’ê²Œ ì¡ì„ ë•Œ ê¸°ìš¸ê¸°ê°€ ì†Œì‹¤ë˜ê±°ë‚˜ ë°œì‚°ë˜ëŠ” ì¦ìƒì„ ì˜ˆë°©ì‹œì¼œì£¼ëŠ” ë°©ë²•ì´ë‹¤. ìì²´ì ìœ¼ë¡œ ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•´ ë“œë¡­ì•„ì›ƒê³¼ ê°™ì€ íš¨ê³¼ë¥¼ ë‚¸ë‹¤. ì°¨ì´ë¼ë©´ ë“œë¡­ì•„ì›ƒì€ ì¼ë¶€ ë°ì´í„°ë¥¼ ë°°ì œí•˜ëŠ” ë°˜ë©´, ë°°ì¹˜ ì •ê·œí™”ëŠ” ì‹ ê²½ë§ ë‚´ë¶€ ë°ì´í„°ì— ì§ì ‘ ì˜í–¥ì„ ì¤€ë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BasicBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">shortcut</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>  <span class="c1"># ì—¬ëŸ¬ nn.Moduleì„ í•˜ë‚˜ì˜ ëª¨ë“ˆë¡œ ë¬¶ëŠ” ì—­í• . ê° ë ˆì´ì–´ë¥¼ ë°ì´í„°ê°€ ìˆœì°¨ì ìœ¼ë¡œ ì§€ë‚˜ê°ˆ ë•Œ ì‚¬ìš©í•˜ë©´ ì½”ë“œ ê°„ê²°í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŒ.
</span>        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">in_planes</span> <span class="o">!=</span> <span class="n">plnaes</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">shortcut</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span>
                          <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                          <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
            <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">shortcut</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div>
<p>ì´ì œ ëª¨ë¸ì„ ì •ì˜í•´ë³´ì. ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ì»¨ë³¼ë£¨ì…˜ê³¼ ë°°ì¹˜ì •ê·œí™” ì¸µì„ ê±°ì¹œ í›„, ì—¬ëŸ¬ BasicBlock ì¸µì„ í†µê³¼í•˜ê³  í‰ê·  í’€ë§ê³¼ ì‹ ê²½ë§ì„ ê±°ì³ ì˜ˆì¸¡ì„ ì¶œë ¥í•˜ë„ë¡ í•˜ì.<br />
BasicBlock í´ë˜ìŠ¤ëŠ” <code class="language-plaintext highlighter-rouge">self._make_layer()</code> í•¨ìˆ˜ë¥¼ í†µí•´ í•˜ë‚˜ì˜ ëª¨ë“ˆë¡œ ê°ì²´í™”í•˜ì—¬ ResNet ëª¨ë¸ì˜ ì£¼ìš” ì¸µì„ ì´ë£¨ë„ë¡ í•  ê²ƒì´ë‹¤.</p>

<p>```python
class ResNet(nn.Module):
    def <strong>init</strong>(self, num_classes=10):
        super(ResNet, self).<strong>init</strong>()
        self.in_planes = 16
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        self.layer1 = self._make_layer(16, 2, stride=1)
        self.layer2 = self._make_layer(32, 2, stride=1)
        self.layer3 = self._make_layer(64, 2, stride=1)
        self.linear = nn.Linear(62, num_classes)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def _make_layer(self, planes, num_blocks, stride):
    strides = [stride] + [1]*(num_blocks-1)
    layer=[]
    for stride in strides:
        layers.append(BasicBlock(self.in_planes, planes, stride))
        self.in_planes = planes
    return nn.Sequential(*layers)
</code></pre></div></div>
:ET