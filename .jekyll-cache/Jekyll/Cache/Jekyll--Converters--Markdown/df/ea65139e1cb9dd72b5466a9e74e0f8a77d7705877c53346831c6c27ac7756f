I"k<p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="3-1-넘파이로-데이터-준비하기">3-1. 넘파이로 데이터 준비하기</h2>
<p>2장에서 썼던 도미와 빙어 데이터를 그대로 활용해보자. 넘파이까지 임포트 할 거다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fish_length</span> <span class="o">=</span> <span class="p">[</span><span class="mf">25.4</span><span class="p">,</span> <span class="mf">26.3</span><span class="p">,</span> <span class="mf">26.5</span><span class="p">,</span> <span class="mf">29.0</span><span class="p">,</span> <span class="mf">29.0</span><span class="p">,</span> <span class="mf">29.7</span><span class="p">,</span> <span class="mf">29.7</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">,</span> <span class="mf">30.7</span><span class="p">,</span> <span class="mf">31.0</span><span class="p">,</span> <span class="mf">31.0</span><span class="p">,</span> 
                <span class="mf">31.5</span><span class="p">,</span> <span class="mf">32.0</span><span class="p">,</span> <span class="mf">32.0</span><span class="p">,</span> <span class="mf">32.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">33.5</span><span class="p">,</span> <span class="mf">33.5</span><span class="p">,</span> <span class="mf">34.0</span><span class="p">,</span> <span class="mf">34.0</span><span class="p">,</span> <span class="mf">34.5</span><span class="p">,</span> <span class="mf">35.0</span><span class="p">,</span> 
                <span class="mf">35.0</span><span class="p">,</span> <span class="mf">35.0</span><span class="p">,</span> <span class="mf">35.0</span><span class="p">,</span> <span class="mf">36.0</span><span class="p">,</span> <span class="mf">36.0</span><span class="p">,</span> <span class="mf">37.0</span><span class="p">,</span> <span class="mf">38.5</span><span class="p">,</span> <span class="mf">38.5</span><span class="p">,</span> <span class="mf">39.5</span><span class="p">,</span> <span class="mf">41.0</span><span class="p">,</span> <span class="mf">41.0</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> 
                <span class="mf">10.5</span><span class="p">,</span> <span class="mf">10.6</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">11.2</span><span class="p">,</span> <span class="mf">11.3</span><span class="p">,</span> <span class="mf">11.8</span><span class="p">,</span> <span class="mf">11.8</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">12.2</span><span class="p">,</span> <span class="mf">12.4</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">14.3</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">]</span>
<span class="n">fish_weight</span> <span class="o">=</span> <span class="p">[</span><span class="mf">242.0</span><span class="p">,</span> <span class="mf">290.0</span><span class="p">,</span> <span class="mf">340.0</span><span class="p">,</span> <span class="mf">363.0</span><span class="p">,</span> <span class="mf">430.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="mf">500.0</span><span class="p">,</span> <span class="mf">390.0</span><span class="p">,</span> <span class="mf">450.0</span><span class="p">,</span> <span class="mf">500.0</span><span class="p">,</span> <span class="mf">475.0</span><span class="p">,</span> <span class="mf">500.0</span><span class="p">,</span> 
                <span class="mf">500.0</span><span class="p">,</span> <span class="mf">340.0</span><span class="p">,</span> <span class="mf">600.0</span><span class="p">,</span> <span class="mf">600.0</span><span class="p">,</span> <span class="mf">700.0</span><span class="p">,</span> <span class="mf">700.0</span><span class="p">,</span> <span class="mf">610.0</span><span class="p">,</span> <span class="mf">650.0</span><span class="p">,</span> <span class="mf">575.0</span><span class="p">,</span> <span class="mf">685.0</span><span class="p">,</span> <span class="mf">620.0</span><span class="p">,</span> <span class="mf">680.0</span><span class="p">,</span> 
                <span class="mf">700.0</span><span class="p">,</span> <span class="mf">725.0</span><span class="p">,</span> <span class="mf">720.0</span><span class="p">,</span> <span class="mf">714.0</span><span class="p">,</span> <span class="mf">850.0</span><span class="p">,</span> <span class="mf">1000.0</span><span class="p">,</span> <span class="mf">920.0</span><span class="p">,</span> <span class="mf">955.0</span><span class="p">,</span> <span class="mf">925.0</span><span class="p">,</span> <span class="mf">975.0</span><span class="p">,</span> <span class="mf">950.0</span><span class="p">,</span> <span class="mf">6.7</span><span class="p">,</span> 
                <span class="mf">7.5</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">9.7</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">8.7</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">9.9</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">12.2</span><span class="p">,</span> <span class="mf">13.4</span><span class="p">,</span> <span class="mf">12.2</span><span class="p">,</span> <span class="mf">19.7</span><span class="p">,</span> <span class="mf">19.9</span><span class="p">]</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<p>넘파이의 <code class="language-plaintext highlighter-rouge">column_stack()</code> 함수는 전달받은 리스트를 일렬로 세우고 이들을 나란히 연결한다. 다음 예를 보자</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">column_stack</span><span class="p">(([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) array([[1, 4],
              [2, 5],
              [3, 6]])
</code></pre></div></div>

<p>두 리스트를 일렬로 세우고 튜플로 전달한다. 이제 <code class="language-plaintext highlighter-rouge">fish_length</code>와 <code class="language-plaintext highlighter-rouge">fish_weight</code>를 합쳐보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fish_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">fish_length</span><span class="p">,</span> <span class="n">fish_weight</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">fish_data</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [[ 25.4 242. ]
        [ 26.3 290. ]
        [ 26.5 340. ]
        [ 29.  363. ]
        [ 29.  430. ]]
</code></pre></div></div>

<p>이제 타깃 데이터를 만들어보자. 2장에서는 원소가 하나인 리스트 <code class="language-plaintext highlighter-rouge">[1]</code>과 <code class="language-plaintext highlighter-rouge">[0]</code> 을 여러 번 곱해서 타깃 데이터를 만들었다. 이번에는 <code class="language-plaintext highlighter-rouge">np.ones()</code>와 <code class="language-plaintext highlighter-rouge">np.zeros()</code> 함수를 쓸 것이다. <code class="language-plaintext highlighter-rouge">np.concatenate()</code> 함수를 사용하여 타깃 데이터를 만들어보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fish_target</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">35</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">14</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="n">fish_target</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
</code></pre></div></div>

<p>2장에서 작성한 코드와 차이점은 이전에는 파이썬 리스트를 사용해 수동으로 만들었지만 이번에는 넘파이를 사용했다는 것이다. 넘파이 배열은 핵심 부분이 C, C++ 같은 저수준 언어로 개발되어 빠르고, 데이터 과학 분야에 알맞게 최적화되어 있다고 한다.</p>

<h2 id="3-2-사이킷런으로-훈련-세트와-테스트-세트-나누기">3-2. 사이킷런으로 훈련 세트와 테스트 세트 나누기</h2>
<p>이번에는 사이킷런을 사용할 것이다. 사이킷런은 머신러닝 모델을 위한 알고리즘뿐만 아니라 다양한 유틸리티 도구도 제공한다. <code class="language-plaintext highlighter-rouge">train_test_split()</code> 함수는 사이킷런의 <code class="language-plaintext highlighter-rouge">model_selection</code> 모듈 아래 있다. 해당 함수를 임포트 하자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</code></pre></div></div>

<p>이전에는 데이터를 무작위로 섞기 전 np.random.seed() 함수를 사용하였다. <code class="language-plaintext highlighter-rouge">train_test_split()</code> 함수는 자체적으로 랜덤 시드를 지정할 수 있는 <code class="language-plaintext highlighter-rouge">random_state</code> 매개변수가 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_input</span><span class="p">,</span> <span class="n">test_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">fish_data</span><span class="p">,</span> <span class="n">fish_target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<p>위와 같이 코딩하면 전달한 2개의 배열 <code class="language-plaintext highlighter-rouge">fish_data</code>, <code class="language-plaintext highlighter-rouge">fish_target</code>이 나뉘어 4개의 배열로 반환된다. 처음 2개는 입력 데이터 <code class="language-plaintext highlighter-rouge">train_input</code>, <code class="language-plaintext highlighter-rouge">test_input</code> 나머지 2개는 <code class="language-plaintext highlighter-rouge">train_target</code>, <code class="language-plaintext highlighter-rouge">test_target</code>이다. 이 함수는 기본적으로 25%를 테스트 세트로 떼어낸다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">train_input</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_input</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">train_target</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_target</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (36, 2) (13, 2)
       (36,) (13,)
</code></pre></div></div>

<p>넘파이 배열의 shape 속성으로 입력 데이터 크기를 출력해보니 맞게 나뉘었다. 도미와 빙어가 잘 섞였는지 테스트 데이터를 출력해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">test_target</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
</code></pre></div></div>

<p>아쉽게도 도미가 10개, 빙어가 3개 들어있다. 빙어의 비율이 조금 모자르다. 전체 데이터에서는 도미와 빙어 비율이 약 2.5:1 였는데, 테스트 데이터에는 비율이 3.3:1 이다.<br />
무작위로 데이터를 나누면 샘플이 이처럼 골고루 섞이지 않을 수 있다. 특히 일부 클래스 개수가 적으면 더욱 그렇다. <code class="language-plaintext highlighter-rouge">train_test_split()</code> 함수는 이런 문제를 해결할 수 있다. <code class="language-plaintext highlighter-rouge">stratify</code> 매개변수에 타깃데이터를 전달하면 클래스 비율에 맞게 데이터를 나눈다. 훈련 데이터가 작거나 특정 클래스의 샘플 개수가 적을 때 특히 유용하다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_input</span><span class="p">,</span> <span class="n">test_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">fish_data</span><span class="p">,</span> <span class="n">fish_target</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">fish_target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">test_target</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]
</code></pre></div></div>

<p>빙어가 하나 더 늘어나 2.25:1이 되었다.</p>

<h2 id="3-3-수상한-도미-한-마리">3-3. 수상한 도미 한 마리</h2>
<p>준비한 데이터로 K-최근접 이웃을 훈련해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">kn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">kn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>
<span class="n">kn</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">test_target</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 1.0
</code></pre></div></div>

<p>이 모델에 새로운 도미 데이터를 넣어보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">kn</span><span class="p">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">150</span><span class="p">]]))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [0.]
</code></pre></div></div>

<p>도미로 분류해야하는데 빙어로 분류했다. 결과가 잘못 산출되었다. 산점도를 그려보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_input</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_input</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'^'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'length'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'weight'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/3-1.png" alt="그림 3-1. 코드 결과" /></p>
<p>그림 3-1. 코드 결과</p>

<p>K-최근접 이웃은 주변의 샘플 중 다수인 클래스를 예측으로 사용한다 하였다. <code class="language-plaintext highlighter-rouge">KNeighborsClassifier</code> 클래스의 이웃 개수인 <code class="language-plaintext highlighter-rouge">n_neighbors</code>의 기본값은 5이다. 즉 5개의 이웃이 반환된다. 한번 확인해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">distances</span><span class="p">,</span> <span class="n">indexes</span> <span class="o">=</span> <span class="n">kn</span><span class="p">.</span><span class="n">kneighbors</span><span class="p">([[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">150</span><span class="p">]])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_input</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_input</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s">'^'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_input</span><span class="p">[</span><span class="n">indexes</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">train_input</span><span class="p">[</span><span class="n">indexes</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'D'</span><span class="p">)</span>  <span class="c1"># 마름모 꼴로 산점도 표시
</span><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'length'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'weight'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/3-2.png" alt="그림 3-2. 코드 결과" /></p>
<p>그림 3-2. 코드 결과</p>

<p>확인해보면 가장 가까운 이웃 5개를 살폈을 때  4개가 빙어 데이터로 분류되어 있다. 참고로 위에서 뽑은 <code class="language-plaintext highlighter-rouge">distances</code> 배열에는 이웃 샘플까지의 거리가 담겨있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [[ 92.00086956 130.48375378 130.73859415 138.32150953 138.39320793]]
</code></pre></div></div>

<h2 id="3-4-기준을-맞춰라">3-4. 기준을 맞춰라</h2>
<p>산점도랑 실제 거리를 비교해보면 뭔가 이상하다. 산점도에서 130대 거리는 92 거리보다 몇배는 더 길어보이는데 130 밖에 안된다니?<br />
이상해보이는 이유는 산점도의 x축은 범위가 10~40인 반면, y축 범위는 0~1000 이기 때문이다. 즉, y축으로 거리가 조금만 멀어져도 아주 큰 값으로 <code class="language-plaintext highlighter-rouge">distances</code> 배열 값이 계산된다는 것이다. x축 범위를 0~1000으로 확장하여 확인해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_input</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_input</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'^'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_input</span><span class="p">[</span><span class="n">indexes</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">train_input</span><span class="p">[</span><span class="n">indexes</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'D'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'length'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'weight'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/3-3.png" alt="그림 3-3. 코드 결과" /></p>
<p>그림 3-3. 코드 결과</p>

<p>이렇게 확인해보니 좀 더 와닿지 않는가?<br />
이렇듯, 두 특성의 값이 놓인 범위가 매우 다르다. 이를 두 특성의 스케일이 다르다고 말한다. 특성 간 스케일은 당연히 다를 수 있다. 그러나 데이터를 표현하는 기준이 다르면 알고리즘은 이를 올바르게 예측할 수 없다. 특히 거리 기반으로 무언가를 판단하는 알고리즘일수록 더욱 그렇다. 이런 알고리즘들은 샘플 간의 거리에 영향을 많이 받으므로 제대로 사용하기 위해서는 특성값을 일정한 기준으로 맞춰주어야 한다. 이런 작업을 <strong>데이터 전처리</strong> 라 한다.<br />
가정 널리 사용하는 전처리 방법 중 하나는 <strong>표준점수</strong>이다. 표준점수는 각 특성값이 0에서 표준편차의 몇 배 만큼 떨어져 있는지를 나타낸다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [ 27.29722222 454.09722222] [  9.98244253 323.29893931]
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">np.mean()</code> 함수는 평균을 계산하고, <code class="language-plaintext highlighter-rouge">np.std()</code> 함수는 표준편차를 계산한다.<code class="language-plaintext highlighter-rouge">axis=0</code>을 지정하여, 행을 따라 각 열의 통계값이 계산되도록 하였다.<br />
이제 표준점수로 변환해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_input</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
</code></pre></div></div>

<p>넘파이는 <code class="language-plaintext highlighter-rouge">train_input</code>의 모든 행에서 <code class="language-plaintext highlighter-rouge">mean</code>에 있는 두 평균값을 빼준다. 그리고 <code class="language-plaintext highlighter-rouge">std</code>에 있는 두 표준편차를 다시 모든 행에 적용한다. 이러한 기능을 <strong>브로드캐스팅</strong> 이라고 한다.</p>

<h2 id="3-5-전처리-데이터로-모델-훈련하기">3-5. 전처리 데이터로 모델 훈련하기</h2>
<p>새로운 데이터 <code class="language-plaintext highlighter-rouge">[25, 150]</code> 도 표준점수를 구하여야 한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new</span> <span class="o">=</span> <span class="p">([</span><span class="mi">25</span><span class="p">,</span> <span class="mi">150</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
</code></pre></div></div>

<p>위에서 구한 표준점수를 산점도로 표현해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_scaled</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'length'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'weight'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/3-4.png" alt="그림 3-4. 코드 결과" /></p>
<p>그림 3-4. 코드 결과</p>

<p>이제 이 데이터로 다시 K-최근접 이웃 모델을 훈련시켜보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">kn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>
</code></pre></div></div>

<p>이제 테스트 세트로 평가를 할 것이다. 주의할 점은, 테스트 세트도 표준점수를 구해줘야 한다는 것인데 이때 훈련 세트로 구한 평균과 표준편차를 이용하여 표준점수를 구해야한다는 것이다. 그렇지 않으면 데이터의 스케일이 같아지지 않으므로 훈련한 모델이 쓸모없게 된다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_input</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
<span class="k">print</span><span class="p">(</span><span class="n">kn</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_scaled</span><span class="p">,</span> <span class="n">test_target</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">kn</span><span class="p">.</span><span class="n">predict</span><span class="p">([</span><span class="n">new</span><span class="p">]))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 1.0
       [1.]
</code></pre></div></div>

<p>이번에는 새로운 데이터에 대해 분류가 잘 되었다. 한번 최근접 이웃 샘플 5개에 대한 데이터를 산출하여 산점도로 나타내보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">distances</span><span class="p">,</span> <span class="n">indexes</span> <span class="o">=</span> <span class="n">kn</span><span class="p">.</span><span class="n">kneighbors</span><span class="p">([</span><span class="n">new</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_scaled</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">new</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'^'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">[</span><span class="n">indexes</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">train_scaled</span><span class="p">[</span><span class="n">indexes</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'length'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'weight'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/3-5.png" alt="그림 3-5. 코드 결과" /></p>
<p>그림 3-5. 코드 결과</p>
:ET