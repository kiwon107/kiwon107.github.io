I"6<p>본 포스팅은 “펭귄브로의 3분 딥러닝, 파이토치맛” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="2-1-오염된-이미지-문제와-복원-방법">2-1. 오염된 이미지 문제와 복원 방법</h2>
<p>오염된 이미지와 이미지 처리 함수 <code class="language-plaintext highlighter-rouge">weird_function()</code>을 이용하여 원본 이미지를 복원하는 문제이다.</p>

<p>다음과 같은 사고 과정을 거쳐보자!</p>
<ol>
  <li>오염된 이미지와 같은 크기의 랜덤 텐서 생성</li>
  <li>랜덤 텐서를 <code class="language-plaintext highlighter-rouge">weird_function()</code> 함수에 입력하여 똑같이 오염된 이미지 생성. 이때 인위적으로 생성한 복사본 이미지를 가설이라고 함!</li>
  <li>가설과 오염된 이미지가 같다면, 무작위 이미지와 오염되기 전 원본 이미지도 같을 것!</li>
  <li>이에따라, <code class="language-plaintext highlighter-rouge">weird_function(random_tensor) = broken_image</code> 관계 성립되도록 만듬.</li>
</ol>

<p>위 사고 과정을 실체화에 성공한다면, random_tensor는 오염되기 전 원본이미지와 거의 비슷한 형태가 될 것이다.<br /></p>

<p>이를 구현하기 위해, 우리는 가설인 random_tensor와 오염되기 전 원본 이미지(<code class="language-plaintext highlighter-rouge">weird_function()</code> 들어가기 전) 사이의 거리 값을 오차로 두어, 이 오차값이 최솟값이 되도록 랜덤 텐서를 바꿔주어야 한다. 랜덤 텐서를 바꿔주는 것은 경사하강법 알고리즘을 사용한다.  <code class="language-plaintext highlighter-rouge">Autograd</code> 패키지를 이용하여 오차를 출력하는 함수의 기울기를 구하고, 이 기울기의 반대 방향으로 가면 오차값이 줄어든다. 이것을 계속 반복하여, 오차값이 최소가 되었을 때의 <code class="language-plaintext highlighter-rouge">random_tensor</code>값을 보면 오염되기 전 원본 이미지와 거의 비슷한 형태가 될 것이다.</p>

<h2 id="2-2-문제-해결과-코드-구현">2-2. 문제 해결과 코드 구현</h2>
<p>파이토치, 맷플롯립을 임포트 한다. 오염된 이미지 파일 로딩하는데 사용할 피클 라이브러리도 임포트 한다. 피클은 파이썬 객체를 파이썬 형태로 저장할 때 쓰는 패키지로, 파이썬에서 기본적으로 제공한다. 오염된 이미지를 파이썬 텐서의 형태로 읽고 이들을 시각화해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">broken_image</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">(</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">'./broken_image_t_p'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">),</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'latin1'</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">broken_image</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningpyt/2-1.png" alt="그림 2-1. 코드 결과" /></p>
<p>그림 2-1. 코드 결과</p>

<p><code class="language-plaintext highlighter-rouge">broken_image</code>는 이미지 행렬을 랭크 1의 벡터로 표현한 텐서 데이터이다. 10,000개의 원소를 [100, 100] 모양의 행렬이 되도록 변환시켜 이를 시각화 하였다.</p>

<p>이제 <code class="language-plaintext highlighter-rouge">weird_function()</code> 함수를 만들자. 저자는 함수를 아직 이해할 필요는 없다고하니, 가볍게 보고 넘어가보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">weird_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">filt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1.</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="o">/</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># 필터! 무슨 필터인지는 아직 모르겠다.
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
        <span class="n">zero_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="o">*</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">h_l</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">zero_tensor</span><span class="p">,</span> <span class="n">h</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># zero_tensor와 h[:-1]을 concatenate 한다
</span>        <span class="n">h_r</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">zero_tensor</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>   <span class="c1"># h[1:]와 zero_tensor를 concatenate 한다
</span>        <span class="n">h</span> <span class="o">=</span> <span class="n">filt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">h</span> <span class="o">+</span> <span class="n">filt</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">h_l</span> <span class="o">+</span> <span class="n">filt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">h_r</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">h</span><span class="p">[</span><span class="n">h</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="mi">2</span><span class="p">:],</span> <span class="n">h</span><span class="p">[:</span><span class="n">h</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="mi">2</span><span class="p">]),</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">h</span>
</code></pre></div></div>

<p>그 다음 무작위 텐서를 <code class="language-plaintext highlighter-rouge">werid_tensor()</code>에 입력하여 얻은 가설 텐서를 오염된 원본 이미지와의 오차를 구하는 함수를 만들 것이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">distance_loss</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">broken_image</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">dist</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">broken_image</span><span class="p">)</span>  <span class="c1"># 두 텐서 사이의 거리 구하는 함수
</span></code></pre></div></div>

<p>이제 무작위 값 갖는 텐서 생성하고 경사하강법에 사용할 학습률을 설정해보자. 학습률은 경사하강법이 여러 번 반복될 때, 한 반복에서 최솟점으로 얼마나 이동할지, 즉 학습을 얼마나 급하게 진행할 것인지 정하는 매개변수이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">random_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.8</span>
</code></pre></div></div>

<p>이제 경사하강법의 for 반복문을 구현해보자. 먼저 random_tensor가 미분 가능하도록 설정하고, 무작위 텐서를 <code class="language-plaintext highlighter-rouge">weird_function()</code> 함수에 통과시켜 가설을 구한다. 그 다음 가설과 오염된 원본 이미지의 오차를 계산하고 오차 함수를 random_tensor에 대해 미분한다. 마지막으로 직접 경사하강법을 구현할 것이기 때문에 파이토치의 자동 기울기 계산을 비활성화하고, <code class="language-plaintext highlighter-rouge">loss.backward()</code>에서 구한 loss의 기울기 방향의 반대쪽으로 random_tensor를 학습률만큼 이동시킨다. for문이 1,000번 반복될 때마다 오차를 출력하도록 할 것이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20000</span><span class="p">):</span>
  <span class="n">random_tensor</span><span class="p">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">hypothesis</span> <span class="o">=</span> <span class="n">weird_function</span><span class="p">(</span><span class="n">random_tensor</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">distance_loss</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">broken_image</span><span class="p">)</span>
  <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

  <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">random_tensor</span> <span class="o">=</span> <span class="n">random_tensor</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">random_tensor</span><span class="p">.</span><span class="n">grad</span>
  
  <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'loss at {} = {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()))</span>
</code></pre></div></div>

<p>반복문이 다 돌았다면 random_tensor가 어떻게 바뀌었는지 확인해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">random_tensor</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningpyt/2-2.png" alt="그림 2-2. 코드 결과" /></p>
<p>그림 2-2. 코드 결과</p>

<p>원본 이미지 타임스퀘어 풍경이 잘 만들어졌다!</p>
:ET