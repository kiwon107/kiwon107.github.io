I"#<p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="10-1-검증-세트">10-1. 검증 세트</h2>
<p>테스트 세트를 사용하지 않으면 모델이 과대적합인지 과소적합인지 판단하기가 어렵다. 테스트 세트를 사용하지 않고 이를 측정하려면 어떻게 해야 할까? 바로 훈련 세트를 나누는 것이다! 훈련 세트로부터 분리된 데이터를 <strong>검증 세트(Validation set)</strong> 라고 한다. 전체 데이터 중, 20%를 테스트 세트, 나머지 80%를 훈련 세트로 만든다. 그리고 이 훈련 세트 중, 다시 20%를 떼어 내어 검증 세트로 만든다. 훈련 세트에서 모델을 훈련하고 검증 세트로 모델을 평가한다. 그리고 나서 테스트하고 싶은 매개변수를 바꿔가며 가장 좋은 모델을 고른다. 그 다음, 해당 매개변수가 괜찮으면, 훈련 세트와 검증 세트를 합쳐 전체 훈련 데이터에서 모델을 다시 훈련한다. 마지막에 테스트 세트에서 최종 점수를 평가한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://bit.ly/wine_csv_data'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">wine</span><span class="p">[[</span><span class="s">'alcohol'</span><span class="p">,</span> <span class="s">'sugar'</span><span class="p">,</span> <span class="s">'pH'</span><span class="p">]].</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">wine</span><span class="p">[</span><span class="s">'class'</span><span class="p">].</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">train_input</span><span class="p">,</span> <span class="n">test_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">sub_input</span><span class="p">,</span> <span class="n">val_input</span><span class="p">,</span> <span class="n">sub_target</span><span class="p">,</span> <span class="n">val_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sub_input</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">val_input</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sub_input</span><span class="p">,</span> <span class="n">sub_target</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">dt</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">sub_input</span><span class="p">,</span> <span class="n">sub_target</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">dt</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">val_input</span><span class="p">,</span> <span class="n">val_target</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (4157, 3) (1040, 3)
       0.9971133028626413
       0.864423076923077
</code></pre></div></div>

<p>위 코드에서는 훈련 세트에서 과대적합이 된 것으로 보인다. 매개변수를 바꿔서 더 좋은 모델을 찾아야한다.</p>

<h2 id="10-2-교차-검증">10-2. 교차 검증</h2>
<p>검증 세트를 만드느라 훈련 세트가 줄었다. 검증 세트를 조금만 떼어 놓자니, 검증 데어터가 부족해 검증 점수는 들쭉날쭉하고 불안정할 것이다. 이때 <strong>교차 검증(Cross validation)</strong>을 이용하면 안정적인 검증 점수를 얻고 훈련에 더 많은 데이터를 사용할 수 있다. 교차 검증은 훈련 세트에서 검증 세트를 여러 번 떼어 내어 평가하는 과정을 반복한다. 그리고 이 반복하여 얻은 점수들을 평균하여 최종 점수를 얻는다. 3-폴드 교차 검증을 예로 들면, 훈련 세트를 3부분으로 나누어 1부분씩 검증 세트로 만들고 3번의 검증 점수를 얻어 평균하면 된다. <strong>k-폴드 교차 검증(K-fold cross validation)</strong>은 이 3부분은 k부분으로 나누어 점수를 k번 내고, 평균하여 점수를 얻는 것이다. 사이킷런에 <code class="language-plaintext highlighter-rouge">cross_validate()</code> 함수를 이용하여 교차 검증을 수행할 수 있다. 기본적으로 5-폴드 교차 검증을 수행한다. 참고로 <code class="language-plaintext highlighter-rouge">cross_val_score()</code> 함수도 있는데, 이 녀석은 <code class="language-plaintext highlighter-rouge">cross_validate()</code>의 결과에서 <code class="language-plaintext highlighter-rouge">test_score</code>값만 반환한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) {'fit_time': array([0.01099277, 0.00800276, 0.01399684, 0.01100063, 0.00998425]), 'score_time': array([0.00099945, 0.00099945, 0.0010035 , 0.00100112, 0.00099993]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">fit_time</code>과 <code class="language-plaintext highlighter-rouge">score_time</code>은 모델을 훈련하는 시간과 검증하는 시간을 의미한다. <code class="language-plaintext highlighter-rouge">test_score</code>는 각 교차 검증의 점수이며, 이를 평균하면 최종 교초 검증 점수를 얻을 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 0.855300214703487
</code></pre></div></div>
:ET