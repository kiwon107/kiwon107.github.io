I"&<p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="14-1-차원과-차원-축소">14-1. 차원과 차원 축소</h2>
<p>13장에서 과일 사진은 10.000개의 픽셀이 있었다. 이는 10,000개의 특성이 있는것과 같다. 이런 특성을 머신러닝 에서는 <strong>차원(Dimension)</strong>이라고 한다. 이 차원을 줄일 수 있다면 저장 공간을 크게 절약할 수 있다. 참고로 다차원 배열에서 차원은 배열의 축 개수이다. 예를 들어 2차원 배열에서는 행과 열이 차원이 된다. 그러나 1차원 배열에서는 원소의 개수가 차원이다.<br /></p>

<p>이제 비지도 학습 작업 중 하나인 <strong>차원 축소(Dimensinoality reduction)</strong>를 알아보자. 특성이 많으면 선형 모델의 성능이 높아지고 훈련 데이터에 쉽게 과적합된다. 차원 축소는 데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터의 크기를 줄이고 지도 학습 모델의 성능은 향상시킬 수 있는 방법이다. 물론 줄어든 차원에서 다시 원본 차원으로 손실을 최대한 줄이며 복원할 수도 있다.</p>

<h2 id="14-2-주성분-분석-소개">14-2. 주성분 분석 소개</h2>
<p><strong>주성분 분석(Principal component analysis)</strong>은 데이터의 분산이 큰 방향을 찾는 것으로 이해할 수 있다. 분산이란 데이터가 널리 퍼져있는 정도를 말한다. 분산이 큰 방향은 데이터로 잘 표현하는 벡터라 생각할 수 있다. 이렇게 분산이 큰 방향의 벡터를 <strong>주성분(Principal component)</strong>라고 한다. 주성분 벡터는 원본 데이터에 있는 어떤 방향이다. 주성분은 원본 차원과 같으며, 원본 데이터는 주성분을 사용하여 차원을 줄일 수 있다.<br />
주성분은 가장 분산이 큰 방향이므로 주성분에 투영하여 바꾼 데이터는 원본이 가지고 있는 특성을 가장 잘 나타낸다. 첫 번째 주성분을 찾고 이 벡터에 수직이며 분산이 가장 큰 다음 방향을 찾으면, 이 벡터가 두 번째 주성분이 된다. 참고로 기술적인 이유 때문에 주성분은 원본 특성의 개수와 샘플 개수 중 작은 값만큼 찾을 수 있다. 비지도 학습은 일반적으로 대량의 데이터에서 수행하므로 원본 특성의 개수만큼 찾을 수 있다고 한다.</p>

<h2 id="14-3-pca-클래스">14-3. PCA 클래스</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">fruits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'fruits_300.npy'</span><span class="p">)</span>
<span class="n">fruits_2d</span> <span class="o">=</span> <span class="n">fruits</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>  <span class="c1"># n_components에 주성분 개수 지정
</span><span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">fruits_2d</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># pca가 찾은 주성분은 components_ 속성에 저장됨
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (50, 10000)
</code></pre></div></div>

<p>보다시피 <code class="language-plaintext highlighter-rouge">pca.components_</code> 배열의 첫 번째 차원이 50이다. 즉 50개의 주성분을 찾은 것이다. draw_fruits() 함수를 만들고, 주성분들의 그림을 그려보자</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">draw_fruits</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">10</span><span class="p">))</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="n">n</span> <span class="k">if</span> <span class="n">rows</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="mi">10</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">cols</span><span class="o">*</span><span class="n">ratio</span><span class="p">,</span> <span class="n">rows</span><span class="o">*</span><span class="n">ratio</span><span class="p">),</span> <span class="n">squeeze</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span><span class="o">*</span><span class="mi">10</span> <span class="o">+</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">10</span> <span class="o">+</span> <span class="n">j</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray_r'</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">draw_fruits</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/14-1.png" alt="그림 14-1. 코드 결과" /></p>
<p>그림 14-1. 코드 결과</p>

<p>원본 데이터에서 가장 분산이 큰 방향을 순서대로 표시했다. 주성분을 찾았으니, 원본 데이터를 주성분에 투영하여 특성 개수를 10,000개에서 50개로 줄일 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">fruits_2d</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">fruits_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">fruits_2d</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">fruits_pca</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (300, 10000)
       (300, 50)
</code></pre></div></div>
:ET