I"C<p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="14-1-차원과-차원-축소">14-1. 차원과 차원 축소</h2>
<p>13장에서 과일 사진은 10.000개의 픽셀이 있었다. 이는 10,000개의 특성이 있는것과 같다. 이런 특성을 머신러닝 에서는 <strong>차원(Dimension)</strong>이라고 한다. 이 차원을 줄일 수 있다면 저장 공간을 크게 절약할 수 있다. 참고로 다차원 배열에서 차원은 배열의 축 개수이다. 예를 들어 2차원 배열에서는 행과 열이 차원이 된다. 그러나 1차원 배열에서는 원소의 개수가 차원이다.<br /></p>

<p>이제 비지도 학습 작업 중 하나인 <strong>차원 축소(Dimensinoality reduction)</strong>를 알아보자. 특성이 많으면 선형 모델의 성능이 높아지고 훈련 데이터에 쉽게 과적합된다. 차원 축소는 데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터의 크기를 줄이고 지도 학습 모델의 성능은 향상시킬 수 있는 방법이다. 물론 줄어든 차원에서 다시 원본 차원으로 손실을 최대한 줄이며 복원할 수도 있다.</p>

<h2 id="14-2-주성분-분석-소개">14-2. 주성분 분석 소개</h2>
<p><strong>주성분 분석(Principal component analysis)</strong>은 데이터의 분산이 큰 방향을 찾는 것으로 이해할 수 있다. 분산이란 데이터가 널리 퍼져있는 정도를 말한다. 분산이 큰 방향은 데이터로 잘 표현하는 벡터라 생각할 수 있다. 이렇게 분산이 큰 방향의 벡터를 <strong>주성분(Principal component)</strong>라고 한다. 주성분 벡터는 원본 데이터에 있는 어떤 방향이다. 주성분은 원본 차원과 같으며, 원본 데이터는 주성분을 사용하여 차원을 줄일 수 있다.<br />
주성분은 가장 분산이 큰 방향이므로 주성분에 투영하여 바꾼 데이터는 원본이 가지고 있는 특성을 가장 잘 나타낸다. 첫 번째 주성분을 찾고 이 벡터에 수직이며 분산이 가장 큰 다음 방향을 찾으면, 이 벡터가 두 번째 주성분이 된다. 참고로 기술적인 이유 때문에 주성분은 원본 특성의 개수와 샘플 개수 중 작은 값만큼 찾을 수 있다. 비지도 학습은 일반적으로 대량의 데이터에서 수행하므로 원본 특성의 개수만큼 찾을 수 있다고 한다.</p>

<h2 id="14-3-pca-클래스">14-3. PCA 클래스</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">fruits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'fruits_300.npy'</span><span class="p">)</span>
<span class="n">fruits_2d</span> <span class="o">=</span> <span class="n">fruits</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>  <span class="c1"># n_components에 주성분 개수 지정
</span><span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">fruits_2d</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># pca가 찾은 주성분은 components_ 속성에 저장됨
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (50, 10000)
</code></pre></div></div>

<p>보다시피 <code class="language-plaintext highlighter-rouge">pca.components_</code> 배열의 첫 번째 차원이 50이다. 즉 50개의 주성분을 찾은 것이다. draw_fruits() 함수를 만들고, 주성분들의 그림을 그려보자</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">draw_fruits</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">10</span><span class="p">))</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="n">n</span> <span class="k">if</span> <span class="n">rows</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="mi">10</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">cols</span><span class="o">*</span><span class="n">ratio</span><span class="p">,</span> <span class="n">rows</span><span class="o">*</span><span class="n">ratio</span><span class="p">),</span> <span class="n">squeeze</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span><span class="o">*</span><span class="mi">10</span> <span class="o">+</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">arr</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">10</span> <span class="o">+</span> <span class="n">j</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray_r'</span><span class="p">)</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">draw_fruits</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/14-1.png" alt="그림 14-1. 코드 결과" /></p>
<p>그림 14-1. 코드 결과</p>

<p>원본 데이터에서 가장 분산이 큰 방향을 순서대로 표시했다. 주성분을 찾았으니, 원본 데이터를 주성분에 투영하여 특성 개수를 10,000개에서 50개로 줄일 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">fruits_2d</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">fruits_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">fruits_2d</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">fruits_pca</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (300, 10000)
       (300, 50)
</code></pre></div></div>

<p>(300, 10000) 크기의 배열이 50개의 주성분을 찾은 PCA 모델을 사용하여 (300, 50) 크기의 배열로 변환됐다.</p>

<h2 id="14-4-원본-데이터-재구성">14-4. 원본 데이터 재구성</h2>
<p>10,000개의 특성이 50개로 줄었으니 어느 정도 손실이 발생할 수밖에 없다. 그러나 분산이 큰 방향으로 데이터를 투영했으므로 원본 데이터를 상당 부분 재구성할 수 있다. <code class="language-plaintext highlighter-rouge">PCA</code>클래스는 <code class="language-plaintext highlighter-rouge">inverse_transform()</code> 메소드를 제공한다. 앞서 50개의 차원으로 축소한 <code class="language-plaintext highlighter-rouge">fruits_pca</code> 데이터를 전달하여 10,000개 특성을 복원하겠다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fruits_inverse</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">fruits_pca</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">fruits_inverse</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (300, 10000)
</code></pre></div></div>

<p>예상대로 10,000개의 특성이 복원되었다. 이제 100 x 100 크기로 바꾸어 그림을 그려보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fruits_reconstruct</span> <span class="o">=</span> <span class="n">fruits_inverse</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">]:</span>
    <span class="n">draw_fruits</span><span class="p">(</span><span class="n">fruits_reconstruct</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">start</span><span class="o">+</span><span class="mi">100</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/14-2.png" alt="그림 14-2. 코드 결과" /></p>
<p class="align-center">그림 14-2. 코드 결과
<img src="/assets/images/machinelearning/14-3.png" alt="그림 14-3. 코드 결과" /></p>
<p class="align-center">그림 14-3. 코드 결과
<img src="/assets/images/machinelearning/14-4.png" alt="그림 14-4. 코드 결과" /></p>
<p>그림 14-4. 코드 결과</p>

<p>모든 과일이 잘 복원되었다. 일부 흐리고 번진 부분도 있지만 이정도면 양호하다.</p>

<h2 id="14-5-설명된-분산">14-5. 설명된 분산</h2>
<p>주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지 기록한 값을 <strong>설명된 분산(Explained variance)</strong>라고 한다. <code class="language-plaintext highlighter-rouge">explained_variance_ratio_</code>에 각 주성분의 설명된 분산 비율이 기록되어 있다. 첫 번째 주성분의 설명된 분산이 가장 크다. 이 분산 비율을 모두 더하면 50개의 주성분으로 표현하고 있는 총 분산 비율을 얻을 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 0.9214529386197033
</code></pre></div></div>

<p>설명된 분산의 비율을 그래프로 그려보면 적절한 주성분의 개수를 찾는데 도움이 된다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/14-5.png" alt="그림 14-5. 코드 결과" /></p>
<p>그림 14-5. 코드 결과</p>

<p>그래프를 보면 거의 10개의 주성분이 대부분의 분산을 표현하고 있다.</p>

<h2 id="14-6-다른-알고리즘과-함께-사용하기">14-6. 다른 알고리즘과 함께 사용하기</h2>
<p>과일 사진 원본 데이터와 PCA로 축소한 데이터를 지도 학습에 적용해 보고 어떠한 차이가 있는지 보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">fruits_2d</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s">'fit_time'</span><span class="p">]))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 0.9966666666666667
       0.6728623867034912
</code></pre></div></div>

:ET