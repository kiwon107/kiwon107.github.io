I"Ñd<p>ë³¸ í¬ìŠ¤íŒ…ì€ â€œí˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹â€ ì±… ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
ì˜ëª»ëœ ë‚´ìš©ì´ ìˆì„ ê²½ìš° ì§€ì í•´ ì£¼ì‹œë©´ ê°ì‚¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.</p>

<h2 id="3-1-ì†ì‹¤-ê³¡ì„ ">3-1. ì†ì‹¤ ê³¡ì„ </h2>
<p><code class="language-plaintext highlighter-rouge">fit()</code> ë©”ì†Œë“œë¡œ ëª¨ë¸ì„ í›ˆë ¨í•  ë•Œ í›ˆë ¨ ê³¼ì •ì´ ìƒì„¸í•˜ê²Œ ì¶œë ¥ë˜ì—ˆë‹¤. ì—í¬í¬, íšŸìˆ˜, ì†ì‹¤, ì •í™•ë„ ë“±ì´ ìˆì—ˆë‹¤. ì¶œë ¥ì˜ ë§ˆì§€ë§‰ì— ë‹¤ìŒê³¼ ê°™ì€ ë©”ì„¸ì§€ë„ ìˆì—ˆë‹¤.<br />
&lt;tensorflow.python.keras.callbacks.History at 0x18340a10e10&gt;<br />
<code class="language-plaintext highlighter-rouge">fit()</code> ë©”ì†Œë“œëŠ” <code class="language-plaintext highlighter-rouge">History</code> í´ë˜ìŠ¤ ê°ì²´ë¥¼ ë°˜í™˜í•œë‹¤. <code class="language-plaintext highlighter-rouge">History</code> ê°ì²´ì—ëŠ” ì†ì‹¤ê³¼ ì •í™•ë„ ê°’ì´ ì €ì¥ë˜ì–´ ìˆë‹¤. ì´ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ ë³´ì.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">),</span> <span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">test_target</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">fashion_mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">train_scaled</span> <span class="o">=</span> <span class="n">train_input</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">train_scaled</span><span class="p">,</span> <span class="n">val_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">val_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<p>ìš°ì„  íŒ¨ì…˜ MNIST ë°ì´í„°ì…‹ì„ í›ˆë ¨ ì„¸íŠ¸ì™€ ê²€ì¦ ì„¸íŠ¸ë¡œ ë‚˜ëˆ´ë‹¤. ê·¸ ë‹¤ìŒ ëª¨ë¸ì„ ë§Œë“œëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">a_layer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">a_layer</span><span class="p">:</span>
        <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">a_layer</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># verbose=1ë¡œ í•˜ë©´ ì—í¬í¬ë§ˆë‹¤ ì§„í–‰ ë§‰ëŒ€ì™€ ì†ì‹¤ ë“±ì˜ ì§€í‘œ ì¶œë ¥, verbose=2ë©´ ì§„í–‰ ë§‰ëŒ€ ë¹¼ê³  ì¶œë ¥í•¨. verbose=0ì€ í›ˆë ¨ ê³¼ì • ì•ˆë‚˜íƒ€ëƒ„.
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(ê²°ê³¼) Model: "sequential"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       flatten (Flatten)            (None, 784)               0         
       _________________________________________________________________
       dense (Dense)                (None, 100)               78500     
       _________________________________________________________________
       dense_1 (Dense)              (None, 10)                1010      
       =================================================================
       Total params: 79,510
       Trainable params: 79,510
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>ë§Œì•½ <code class="language-plaintext highlighter-rouge">model_fn()</code> í•¨ìˆ˜ì— ì¼€ë¼ìŠ¤ ì¸µì„ ì¶”ê°€í•˜ë©´ ì€ë‹‰ì¸µ ë’¤ì— ë˜ í•˜ë‚˜ì˜ ì¸µì„ ì¶”ê°€í•  ìˆ˜ ìˆë„ë¡ í–ˆë‹¤. history ê°ì²´ì—ëŠ” í›ˆë ¨ ì¸¡ì •ê°’ì´ ë‹´ê²¨ ìˆëŠ” history ë”•ì…”ë„ˆë¦¬ê°€ ë“¤ì–´ìˆë‹¤.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(ê²°ê³¼) dict_keys(['loss', 'accuracy'])
</code></pre></div></div>

<p>ë³´ë©´ ì†ì‹¤ê³¼ ì •í™•ë„ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ëŠ”ê±¸ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì¼€ë¼ìŠ¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì—í¬í¬ë§ˆë‹¤ ì†ì‹¤ì„ ê³„ì‚°í•œë‹¤. ì •í™•ë„ëŠ” <code class="language-plaintext highlighter-rouge">compile()</code> ë©”ì†Œë“œì—ì„œ <code class="language-plaintext highlighter-rouge">metrics</code> ë§¤ê°œë³€ìˆ˜ì— â€˜accuracyâ€™ë¥¼ ì¶”ê°€í–ˆê¸° ë•Œë¬¸ì— history ì†ì„±ì— í¬í•¨ë˜ì–´ ìˆë‹¤. ê·¸ë˜í”„ë¡œ ì†ì‹¤ê°’ì„ ë‚˜íƒ€ë‚´ë³´ì.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/3-1.png" alt="ê·¸ë¦¼ 3-1. ì½”ë“œ ê²°ê³¼" /></p>
<p>ê·¸ë¦¼ 3-1. ì½”ë“œ ê²°ê³¼</p>

<p>ì •í™•ë„ë„ ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ë³´ì,</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/3-2.png" alt="ê·¸ë¦¼ 3-2. ì½”ë“œ ê²°ê³¼" /></p>
<p>ê·¸ë¦¼ 3-2. ì½”ë“œ ê²°ê³¼</p>

<p>ì—í¬í¬ë§ˆë‹¤ ì†ì‹¤ì´ ê°ì†Œí•˜ê³  ì •í™•ë„ê°€ í–¥ìƒë˜ì—ˆë‹¤ëŠ”ê±¸ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ë²ˆì—ëŠ” ì—í¬í¬ë¥¼ 20ìœ¼ë¡œ ëŠ˜ë ¤ì„œ ì†ì‹¤ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë³´ì.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/3-3.png" alt="ê·¸ë¦¼ 3-3. ì½”ë“œ ê²°ê³¼" /></p>
<p>ê·¸ë¦¼ 3-3. ì½”ë“œ ê²°ê³¼</p>

<h2 id="3-2-ê²€ì¦-ì†ì‹¤">3-2. ê²€ì¦ ì†ì‹¤</h2>
<p>ì—í¬í¬ì— ë”°ë¥¸ ê³¼ëŒ€ì í•©ê³¼ ê³¼ì†Œì í•©ì„ íŒŒì•…í•˜ë ¤ë©´ í›ˆë ¨ ì„¸íŠ¸ì— ëŒ€í•œ ì ìˆ˜ ë¿ë§Œ ì•„ë‹ˆë¼, ê²€ì¦ ì„¸íŠ¸ì— ëŒ€í•œ ì ìˆ˜ë„ í•„ìš”í•˜ë‹¤. ì°¸ê³ ë¡œ ì‹ ê²½ë§ ëª¨ë¸ì´ ìµœì í™” í•˜ëŠ” ëŒ€ìƒì€ ì •í™•ë„ê°€ ì•„ë‹Œ ì†ì‹¤ í•¨ìˆ˜ì´ë‹¤. ì†ì‹¤ í•¨ìˆ˜ì— ë¹„ë¡€í•˜ì—¬ ì •í™•ë„ê°€ ë†’ì•„ì§€ì§€ ì•ŠëŠ” ê²½ìš°ë„ ìˆë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì´ ì˜ í›ˆë ¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ì •í™•ë„ë³´ë‹¤ëŠ” ì†ì‹¤ í•¨ìˆ˜ì˜ ê°’ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ë” ë‚«ë‹¤. <code class="language-plaintext highlighter-rouge">validation_data</code> ë§¤ê°œë³€ìˆ˜ì— ê²€ì¦ì— ì‚¬ìš©í•  ì…ë ¥ê³¼ íƒ€ê¹ƒê°’ì„ íŠœí”Œë¡œ ë§Œë“¤ì–´ ì „ë‹¬í•´ë³´ì.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_scaled</span><span class="p">,</span> <span class="n">val_target</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(ê²°ê³¼) dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
</code></pre></div></div>

<p>ê²€ì¦ ì„¸íŠ¸ì— ëŒ€í•œ ì†ì‹¤ê°’ì€ â€˜val_lossâ€™ì— ë“¤ì–´ìˆë‹¤. ì •í™•ë„ëŠ” â€˜val_accuracyâ€™ì— ìˆë‹¤. ê·¸ë˜í”„ë¡œ ì´ ë‘˜ì„ ë‚˜íƒ€ë‚´ë³´ì.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/3-4.png" alt="ê·¸ë¦¼ 3-4. ì½”ë“œ ê²°ê³¼" /></p>
<p>ê·¸ë¦¼ 3-4. ì½”ë“œ ê²°ê³¼</p>

<p>ì „í˜•ì ì¸ ê³¼ëŒ€ì í•© ëª¨ë¸ì´ ë§Œë“¤ì–´ì¡Œë‹¤. ê²€ì¦ ì†ì‹¤ì´ ìƒìŠ¹í•˜ëŠ” ì‹œì ì„ ë’¤ë¡œ ëŠ¦ì¶”ë©´ ê²€ì¦ ì„¸íŠ¸ì— ëŒ€í•œ ì†ì‹¤ì´ ì¤„ì–´ë“¤ê³  ì •í™•ë„ë„ ì¦ê°€í•  ê²ƒì´ë‹¤. ì˜µí‹°ë§ˆì´ì € í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì—¬ ê³¼ëŒ€ì í•©ì„ ì™„í™”ì‹œì¼œë³´ì. ì˜µí‹°ë§ˆì´ì €ë¥¼ <code class="language-plaintext highlighter-rouge">RMSprop</code>ì—ì„œ <code class="language-plaintext highlighter-rouge">Adam</code>ìœ¼ë¡œ ë³€ê²½í•´ë³´ì.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_scaled</span><span class="p">,</span> <span class="n">val_target</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/3-5.png" alt="ê·¸ë¦¼ 3-5. ì½”ë“œ ê²°ê³¼" /></p>
<p>ê·¸ë¦¼ 3-5. ì½”ë“œ ê²°ê³¼</p>

<p>ê³¼ëŒ€ì í•©ì´ í›¨ì”¬ ì¤„ì—ˆë‹¤. ì´ëŠ” <code class="language-plaintext highlighter-rouge">Adam</code> ì˜µí‹°ë§ˆì´ì €ê°€ ì´ ë°ì´í„°ì…‹ì— ì˜ ë§ëŠ”ë‹¤ëŠ” ê²ƒì´ë‹¤. ë” ë‚˜ì€ ì†ì‹¤ ê³¡ì„ ì„ ì–»ìœ¼ë ¤ë©´ í•™ìŠµë¥ ì„ ì¡°ì •í•´ì„œ ë‹¤ì‹œ ì‹œë„í•´ ë³¼ ìˆ˜ ìˆë‹¤.</p>

<h2 id="3-3-ë“œë¡­ì•„ì›ƒ">3-3. ë“œë¡­ì•„ì›ƒ</h2>
<p><strong>ë“œë¡­ì•„ì›ƒ(Dropout)</strong>ì€ ì¼ë¶€ ë‰´ëŸ°ì„ ëœë¤í•˜ê²Œ êº¼ì„œ ê³¼ëŒ€ì í•©ì„ ë§‰ëŠ”ë‹¤. ë‰´ëŸ°ì€ ëœë¤í•˜ê²Œ ë“œë¡­ì•„ì›ƒë˜ê³  ì–¼ë§ˆë‚˜ ë§ì€ ë‰´ëŸ°ì„ ë“œë¡­í• ì§€ëŠ” ìš°ë¦¬ê°€ ì •í•´ì•¼ í•  ë˜ ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì´ë‹¤. ë“œë¡­ì•„ì›ƒì€ ì¼ë¶€ ë‰´ëŸ°ì´ ëœë¤í•˜ê²Œ êº¼ì§€ê²Œ ë§Œë“¤ì–´ íŠ¹ì • ë‰´ëŸ°ì— ê³¼ëŒ€í•˜ê²Œ ì˜ì¡´í•˜ëŠ” ê²ƒì„ ì¤„ì´ê³  ëª¨ë“  ì…ë ¥ì— ëŒ€í•´ ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ë„ë¡ í•œë‹¤. ì¼€ë¼ìŠ¤ì—ëŠ” ë“œë¡­ì•„ì›ƒì„ <code class="language-plaintext highlighter-rouge">keras.layers</code> íŒ¨í‚¤ì§€ ì•ˆì— <code class="language-plaintext highlighter-rouge">Dropout</code> í´ë˜ìŠ¤ë¡œ ì œê³µí•œë‹¤. ì–´ë–¤ ì¸µì˜ ë’¤ì— ë“œë¡­ì•„ì›ƒì„ ë‘ì–´ ì´ ì¸µì˜ ì¶œë ¥ì„ ëœë¤í•˜ê²Œ 0ìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒì´ë‹¤. ë“œë¡­ì•„ì›ƒì´ ì¸µì²˜ëŸ¼ ì‚¬ìš©ë˜ì§€ë§Œ, í›ˆë ¨ë˜ëŠ” ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ì—†ë‹¤.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">model_fn</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(ê²°ê³¼) Model: "sequential_4"
       _________________________________________________________________
       Layer (type)                 Output Shape              Param #   
       =================================================================
       flatten_4 (Flatten)          (None, 784)               0         
       _________________________________________________________________
       dense_8 (Dense)              (None, 100)               78500     
       _________________________________________________________________
       dropout (Dropout)            (None, 100)               0         
       _________________________________________________________________
       dense_9 (Dense)              (None, 10)                1010      
       =================================================================
       Total params: 79,510
       Trainable params: 79,510
       Non-trainable params: 0
       _________________________________________________________________
</code></pre></div></div>

<p>ë³´ë‹¤ì‹œí”¼ ì€ë‹‰ì¸µ ë’¤ ì¶”ê°€ëœ ë“œë¡­ì•„ì›ƒ ì¸µì€ í›ˆë ¨ë˜ëŠ” ëª¨ë¸ íŒŒë¼ë¯¸í„°ê°€ ì—†ë‹¤. ë˜í•œ ì…ë ¥ê³¼ ì¶œë ¥ì˜ í¬ê¸°ë„ ë™ì¼í•˜ë‹¤. ì¼ë¶€ ë‰´ëŸ°ì˜ ì¶œë ¥ì„ 0ìœ¼ë¡œ ë§Œë“¤ì§€ë§Œ ì „ì²´ ì¶œë ¥ ë°°ì—´ì˜ í¬ê¸°ë¥¼ ë°”ê¾¸ì§€ëŠ” ì•ŠëŠ”ë‹¤. ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ì ì€ í›ˆë ¨ì´ ëë‚œ ë’¤ í‰ê°€ë‚˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ë•ŒëŠ” ë“œë¡­ì•„ì›ƒì„ ì ìš©í•˜ì§€ ë§ì•„ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. í›ˆë ¨ëœ ëª¨ë“  ë‰´ëŸ°ì„ ì‚¬ìš©í•´ì•¼ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•˜ë‹¤. í…ì„œí”Œë¡œì™€ ì¼€ë¼ìŠ¤ëŠ” ëª¨ë¸ì„ í‰ê°€ì™€ ì˜ˆì¸¡ì— ì‚¬ìš©ì‹œ ìë™ìœ¼ë¡œ ë“œë¡­ì•„ì›ƒì„ ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_scaled</span><span class="p">,</span> <span class="n">val_target</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'val'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/3-6.png" alt="ê·¸ë¦¼ 3-6. ì½”ë“œ ê²°ê³¼" /></p>
<p>ê·¸ë¦¼ 3-6. ì½”ë“œ ê²°ê³¼</p>

:ET