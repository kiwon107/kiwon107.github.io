I"E<p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="10-1-검증-세트">10-1. 검증 세트</h2>
<p>테스트 세트를 사용하지 않으면 모델이 과대적합인지 과소적합인지 판단하기가 어렵다. 테스트 세트를 사용하지 않고 이를 측정하려면 어떻게 해야 할까? 바로 훈련 세트를 나누는 것이다! 훈련 세트로부터 분리된 데이터를 <strong>검증 세트(Validation set)</strong> 라고 한다. 전체 데이터 중, 20%를 테스트 세트, 나머지 80%를 훈련 세트로 만든다. 그리고 이 훈련 세트 중, 다시 20%를 떼어 내어 검증 세트로 만든다. 훈련 세트에서 모델을 훈련하고 검증 세트로 모델을 평가한다. 그리고 나서 테스트하고 싶은 매개변수를 바꿔가며 가장 좋은 모델을 고른다. 그 다음, 해당 매개변수가 괜찮으면, 훈련 세트와 검증 세트를 합쳐 전체 훈련 데이터에서 모델을 다시 훈련한다. 마지막에 테스트 세트에서 최종 점수를 평가한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://bit.ly/wine_csv_data'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">wine</span><span class="p">[[</span><span class="s">'alcohol'</span><span class="p">,</span> <span class="s">'sugar'</span><span class="p">,</span> <span class="s">'pH'</span><span class="p">]].</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">wine</span><span class="p">[</span><span class="s">'class'</span><span class="p">].</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">train_input</span><span class="p">,</span> <span class="n">test_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">sub_input</span><span class="p">,</span> <span class="n">val_input</span><span class="p">,</span> <span class="n">sub_target</span><span class="p">,</span> <span class="n">val_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sub_input</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">val_input</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sub_input</span><span class="p">,</span> <span class="n">sub_target</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">dt</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">sub_input</span><span class="p">,</span> <span class="n">sub_target</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">dt</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">val_input</span><span class="p">,</span> <span class="n">val_target</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (4157, 3) (1040, 3)
       0.9971133028626413
       0.864423076923077
</code></pre></div></div>

<p>위 코드에서는 훈련 세트에서 과대적합이 된 것으로 보인다. 매개변수를 바꿔서 더 좋은 모델을 찾아야한다.</p>

<h2 id="10-2-교차-검증">10-2. 교차 검증</h2>
<p>검증 세트를 만드느라 훈련 세트가 줄었다. 검증 세트를 조금만 떼어 놓자니, 검증 데어터가 부족해 검증 점수는 들쭉날쭉하고 불안정할 것이다. 이때 <strong>교차 검증(Cross validation)</strong>을 이용하면 안정적인 검증 점수를 얻고 훈련에 더 많은 데이터를 사용할 수 있다. 교차 검증은 훈련 세트에서 검증 세트를 여러 번 떼어 내어 평가하는 과정을 반복한다. 그리고 이 반복하여 얻은 점수들을 평균하여 최종 점수를 얻는다. 3-폴드 교차 검증을 예로 들면, 훈련 세트를 3부분으로 나누어 1부분씩 검증 세트로 만들고 3번의 검증 점수를 얻어 평균하면 된다. <strong>k-폴드 교차 검증(K-fold cross validation)</strong>은 이 3부분은 k부분으로 나누어 점수를 k번 내고, 평균하여 점수를 얻는 것이다. 사이킷런에 <code class="language-plaintext highlighter-rouge">cross_validate()</code> 함수를 이용하여 교차 검증을 수행할 수 있다. 기본적으로 5-폴드 교차 검증을 수행한다. 참고로 <code class="language-plaintext highlighter-rouge">cross_val_score()</code> 함수도 있는데, 이 녀석은 <code class="language-plaintext highlighter-rouge">cross_validate()</code>의 결과에서 <code class="language-plaintext highlighter-rouge">test_score</code>값만 반환한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) {'fit_time': array([0.01099277, 0.00800276, 0.01399684, 0.01100063, 0.00998425]), 'score_time': array([0.00099945, 0.00099945, 0.0010035 , 0.00100112, 0.00099993]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">fit_time</code>과 <code class="language-plaintext highlighter-rouge">score_time</code>은 모델을 훈련하는 시간과 검증하는 시간을 의미한다. <code class="language-plaintext highlighter-rouge">test_score</code>는 각 교차 검증의 점수이며, 이를 평균하면 최종 교초 검증 점수를 얻을 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 0.855300214703487
</code></pre></div></div>

<p>주의해야할 점은, <code class="language-plaintext highlighter-rouge">cross_validate()</code> 함수 적용시, 훈련 세트를 다시 훈련 세트와 검증 세트로 나눠서는 안된다. 훈련 세트만 넣어주면 알아서 검증 세트를 계속 분할하여 테스트 해준다. 만약 교차 검증할 때 훈련 세트를 한번 섞어주고 싶다면, <strong>분할기(Splitter)</strong>를 지정해야 한다. 회귀 모델일 경우, <strong>KFold 분할기</strong>를 사용하고, 분류 모델일 경우, <strong>StratifiedKFold</strong>를 사용하여 타깃 클래스를 골고루 나눈다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">StratifiedKFold</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 0.855300214703487
</code></pre></div></div>

<p>만약 10-폴드 교차 검증을 수행하고 싶다면 다음과 같이 작성하자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">splitter</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">splitter</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 0.8574181117533719
</code></pre></div></div>

<p>이제 테스트 세트를 사용하지 않고 교차 검증으로 좋은 모델을 고르자!</p>

<h2 id="10-3-하이퍼파라미터-튜닝">10-3. 하이퍼파라미터 튜닝</h2>
<p>하이퍼파라미터는 모델이 학습할 수 없어서 사용자가 지정해야만 하는 파라미터를 의미한다. 보통 하이퍼파라미터는 모두 클래스나 메소드의 매개변수로 표현된다. 하이퍼파라미터를 튜닝할 때는 먼저 라이브러리가 제공하는 기본값을 그대로 사용하여 모델을 훈련한다. 그 다음 검증 세트의 점수나 교차 검증을 통해서 매개변수를 조금씩 바꿔나간다. 매개변수를 바꿔가며 모델을 훈련하고 교차 검증을 수행한다. 참고로 <code class="language-plaintext highlighter-rouge">AutoML</code> 이라는 기술이 있는데, 이는 사람의 개입 없이 하이퍼파라미터 튜닝을 자동으로 수행하는 기술을 말한다.</p>

<p>결정 트리를 예로 보자. <code class="language-plaintext highlighter-rouge">max_depth</code>를 최적값으로 고정하고 <code class="language-plaintext highlighter-rouge">min_samples_split</code>을 바꿔가며 최적의 값을 찾는다. 이렇게 한 매개변수의 최적값을 찾고 다른 매개변수의 최적값을 찾아도 될까? 아쉽게도 <code class="language-plaintext highlighter-rouge">max_depth</code>의 최적값은 <code class="language-plaintext highlighter-rouge">min_samples_split</code> 매개변수가 바뀔 경우 함께 달라진다. 즉, 두 매개변수를 동시에 바꿔가며 최적값을 찾아야 하는 것이다. 매개변수가 많을수록 문제는 더 복잡해진다. 사이킷런에서는 이런 경우를 대비해 <strong>그리드 서치(Grid search)</strong>를 제공한다. <code class="language-plaintext highlighter-rouge">GridSearchCV</code> 클래스는 하이퍼파라미터 탐색과 교차 검증을 한 번에 수행한다. <code class="language-plaintext highlighter-rouge">cross_validate()</code> 함수를 호출할 필요 없이 말이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s">'min_impurity_decrease'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.0002</span><span class="p">,</span> <span class="mf">0.0003</span><span class="p">,</span> <span class="mf">0.0004</span><span class="p">,</span> <span class="mf">0.0005</span><span class="p">]}</span>  <span class="c1"># min_impurity_decrease 값 바꿔가며 총 5번 실행
</span><span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> <span class="n">params</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># cv 매개변수 기본값은 5, n_jobs로 병렬 실행에 사용할 CPU 코어 수 지정! 기본값은 1이며 -1 설정하면 사용 가능한 모든 코어 사용
</span><span class="n">gs</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">gs</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="k">print</span><span class="p">(</span><span class="n">dt</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 0.9615162593804117
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">best_params_</code> 속성에 최적의 매개변수 값 들어있다. 각 매개변수에서 수행한 교차 검증의 평균 점수는 <code class="language-plaintext highlighter-rouge">cv_results_</code> 속성의 ‘mean_test_score’키에 저장되어 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">gs</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gs</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) {'min_impurity_decrease': 0.0001}
       [0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">cv_results_</code> 속성의 ‘params’ 키에는</p>
:ET