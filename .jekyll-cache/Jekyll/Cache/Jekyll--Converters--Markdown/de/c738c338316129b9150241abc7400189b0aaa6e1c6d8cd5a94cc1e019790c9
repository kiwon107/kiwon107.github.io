I"]U<p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="7-1-럭키백의-확률">7-1. 럭키백의 확률</h2>
<p>럭키백에 들어간 생선의 크기, 무게 등이 주어졌을 때, 7개 생선에 대한 확률을 출력해야 한다고 하자. 길이, 높이, 두께, 대각선 길이, 무게를 특성으로 사용할 수 있다고 한다. 사이킷런의 K-최근접 이웃 분류기로 클래스 확률을 계산할 수는 있다. 한번 확률을 출력해보자.</p>

<h2 id="7-2-데이터-준비">7-2. 데이터 준비</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">fish</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'http://bit.ly/fish_csv_data'</span><span class="p">)</span>
<span class="n">fish</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>  <span class="c1"># 처음 5개 행 출력
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과)  	Species	Weight	Length	Diagonal	Height	Width
        0	Bream	242.0	25.4	30.0	    11.5200	4.0200
        1	Bream	290.0	26.3	31.2	    12.4800	4.3056
        2	Bream	340.0	26.5	31.1	    12.3778	4.6961
        3	Bream	363.0	29.0	33.5	    12.7300	4.4555
        4	Bream	430.0	29.0	34.0	    12.4440	5.1340
</code></pre></div></div>

<p>판다스의 <code class="language-plaintext highlighter-rouge">raed_csv()</code> 함수는 csv 파일을 데이터프레임으로 변환한다. 데이터프레임은 판다스에서 제공하는 표 형식의 주요 데이터 구조이다. 넘파이 행렬처럼 열과 행으로 이루어져 있다. 데이터프레임은 통계와 그래프를 위한 메소드를 풍부하게 제공하며, 넘파이와 사이킷런과의 호환성이 좋다.</p>

<p>이제 Species 열에서 고유한 값을 추출해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">fish</span><span class="p">[</span><span class="s">'Species'</span><span class="p">]))</span>  <span class="c1"># unique() 함수는 데이터의 고유값들에 어떤 종류가 있는지 알고 싶을 때 사용!
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) ['Bream' 'Roach' 'Whitefish' 'Parkki' 'Perch' 'Pike' 'Smelt']
</code></pre></div></div>

<p>Species 열을 타깃으로 만들고 나머지 5개를 열을 입력 데이터로 사용하자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fish_input</span> <span class="o">=</span> <span class="n">fish</span><span class="p">[[</span><span class="s">'Weight'</span><span class="p">,</span> <span class="s">'Length'</span><span class="p">,</span> <span class="s">'Diagonal'</span><span class="p">,</span> <span class="s">'Height'</span><span class="p">,</span> <span class="s">'Width'</span><span class="p">]].</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">fish_target</span> <span class="o">=</span> <span class="n">fish</span><span class="p">[</span><span class="s">'Species'</span><span class="p">].</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">fish_input</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [[242.      25.4     30.      11.52     4.02  ]
        [290.      26.3     31.2     12.48     4.3056]
        [340.      26.5     31.1     12.3778   4.6961]
        [363.      29.      33.5     12.73     4.4555]
        [430.      29.      34.      12.444    5.134 ]]
</code></pre></div></div>

<p>그 다음, 데이터를 훈련 세트와 테스트 세트로 나누고, 각 세트를 표준화 전처리 하자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">train_input</span><span class="p">,</span> <span class="n">test_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_target</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">fish_input</span><span class="p">,</span> <span class="n">fish_target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">ss</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">ss</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_input</span><span class="p">)</span>
<span class="n">train_scaled</span> <span class="o">=</span> <span class="n">ss</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_input</span><span class="p">)</span>
<span class="n">test_scaled</span> <span class="o">=</span> <span class="n">ss</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="7-3-k-최근접-이웃-분류기의-확률-예측">7-3. K-최근접 이웃 분류기의 확률 예측</h2>
<p>최근접 이웃 개수인 k를 지정하여 K-최근접 이웃 분류기가 예측한 확률을 구해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">kn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">kn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">kn</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">train_scaled</span><span class="p">,</span> <span class="n">train_target</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">kn</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_scaled</span><span class="p">,</span> <span class="n">test_target</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) 0.8907563025210085
       0.85
</code></pre></div></div>

<p>일단 결과는 이렇게 나왔는데, 참고만 하고 점수에 대해서는 잊자.<br />
타깃 데이터 2개 이상의 클래스가 포함된 문제를 <strong>다중 분류(Multi-class classification)</strong> 라고 한다. 이진 분류를 사용했을 때는 양성 클래스와 음성 클래스를 각각 1과 0으로 지정하여 타깃 데이터를 만들었다. 다중 분류에서도 타깃값을 숫자로 바꾸어 입력할 수 있다. 그러나 사이킷런에서는 문자열로 된 타깃값을 그대로 사용할 수 있다! 이 때, 타깃값을 그대로 사이킷런 모델에 전달하면 순서가 자동으로 알파벳 순 정렬된다. 즉, <code class="language-plaintext highlighter-rouge">pd.unique(fish['Species'])</code>로 출력했던 순서와 다르다!</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">kn</span><span class="p">.</span><span class="n">classes_</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) ['Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish']
</code></pre></div></div>

<p>테스트 세트에 있는 처음 5개 샘플의 타깃을 예측해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">kn</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_scaled</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">test_target</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) ['Perch' 'Smelt' 'Pike' 'Perch' 'Perch']
       ['Perch' 'Smelt' 'Pike' 'Whitefish' 'Perch']
</code></pre></div></div>

<p>사이킷런의 분류 모델은 <code class="language-plaintext highlighter-rouge">predict_proba()</code> 메소드로 클래스별 확률값을 반환할 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">proba</span> <span class="o">=</span> <span class="n">kn</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_scaled</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="n">proba</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>  <span class="c1"># decimals 매개변수로 유지할 소수점 아래 자릿수 지정 가능!
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [[0.     0.     1.     0.     0.     0.     0.    ]
        [0.     0.     0.     0.     0.     1.     0.    ]
        [0.     0.     0.     1.     0.     0.     0.    ]
        [0.     0.     0.6667 0.     0.3333 0.     0.    ]
        [0.     0.     0.6667 0.     0.3333 0.     0.    ]]
</code></pre></div></div>

<p>위 5개 데이터 중, 4번째 데이터와 가까운 이웃 샘플 3개에 대한 타겟을 보면 위 코드 결과가 맞다는 것을 확인할 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">distances</span><span class="p">,</span> <span class="n">indexes</span> <span class="o">=</span> <span class="n">kn</span><span class="p">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">test_scaled</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">train_target</span><span class="p">[</span><span class="n">indexes</span><span class="p">])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [['Roach' 'Perch' 'Perch']]
</code></pre></div></div>

<p>K-최근접 이웃은 결국 이웃 샘플 개수를 몇개로 설정하느냐에 따라 확률값이 고정되어 출력된다. 다른 방법은 없을까?</p>

<h2 id="7-4-로지스틱-회귀">7-4. 로지스틱 회귀</h2>
<p><strong>로지스틱 회귀</strong>는 선형 회귀와 동일하게 선형 방정식을 학습하는 <strong>분류 모델</strong>이다.<br />
$ z = a\times (Weight) + b\times (length) + c\times (Diagonal) + d\times (Height) + e\times (Width) + f $
여기에서 $a, b, c, d, e$는 가중치이다. $z$는 어떤 값도 가능하지만, 확률이 되려면 0~1 사이 값이 되어야 한다. $z$가 아주 큰 음수이면 0, 아주 큰 양수이면 1이 되도록 바꾸는 기능을 담당하는 함수가 바로 <strong>시그모이드 함수(Sigmoid function)</strong> 또는 <strong>로지스틱 함수(Logistic function)</strong>이다.<br />
$ \phi = \frac{1}{1+e^{-z}} $ <br />
z가 무한하게 큰 움수이면 이 함수는 0에 가까워지고, z가 무한하게 큰 양수가 되면 1에 가까워진다. z가 0이 될 때는 0.5가 되며, z가 어떤 값이 되더라도 $ \phi $는절대 0~1 사이의 범위를 벗어날 수 없다. 그래프를 시각화 하면 다음과 같다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">phi</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">phi</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'z'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'phi'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/machinelearning/7-1.png" alt="그림 7-1. 코드 결과" /></p>
<p>그림 7-1. 코드 결과</p>

<p>이진 분류를 해보자. 시그모이드 함수 출력이 0.5보다 크면 양성 클래스, 0.5보다 작으면 음성 클래스로 판단하도록 만들자.</p>

<h2 id="7-5-로지스틱-회귀로-이진-분류-수행하기">7-5. 로지스틱 회귀로 이진 분류 수행하기</h2>
<p>넘파이 배열은 True, False 값을 전달하여 행을 선택할 수 있다. 이를 <strong>불리언 인덱싱(Boolean indexing)</strong> 라고 한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">char_arr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="s">'A'</span><span class="p">,</span> <span class="s">'B'</span><span class="p">,</span> <span class="s">'C'</span><span class="p">,</span> <span class="s">'D'</span><span class="p">,</span> <span class="s">'E'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">char_arr</span><span class="p">[[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">False</span><span class="p">]])</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) ['A' 'C']
</code></pre></div></div>

<p>이를 이용해서, 도미와 빙어 클래스 데이터 및 라벨만 골라내도록 하자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bream_smelt_indexes</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_target</span> <span class="o">==</span> <span class="s">'Bream'</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">train_target</span> <span class="o">==</span> <span class="s">'Smelt'</span><span class="p">)</span>
<span class="n">train_bream_smelt</span> <span class="o">=</span> <span class="n">train_scaled</span><span class="p">[</span><span class="n">bream_smelt_indexes</span><span class="p">]</span>
<span class="n">target_bream_smelt</span> <span class="o">=</span> <span class="n">train_target</span><span class="p">[</span><span class="n">bream_smelt_indexes</span><span class="p">]</span>
</code></pre></div></div>

<p>이제 로지스틱 회귀 모델을 훈련하여 테스트셋 일부 결과를 출력해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_bream_smelt</span><span class="p">,</span> <span class="n">target_bream_smelt</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_bream_smelt</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">train_bream_smelt</span><span class="p">[:</span><span class="mi">5</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">lr</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) ['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']
       [[0.99759855 0.00240145]
        [0.02735183 0.97264817]
        [0.99486072 0.00513928]
        [0.98584202 0.01415798]
        [0.99767269 0.00232731]]
       ['Bream' 'Smelt']
       [[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]
</code></pre></div></div>

<p>위 코드 결과에 따라 로지스틱 회귀 모델이 학습한 방정식은 다음과 같다.
$ z = -0.404\times (Weight) + -0.576\times (length) + -0.663\times (Diagonal) + 1.013\times (Height) + -0.732\times (Width) + -2.161 $<br /></p>

<p>처음 5개 샘플에 위 식을 대입하여 나온 z값을 출력해보고, 이를 시그모이드 함수에도 넣어보자!</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">decisions</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">train_bream_smelt</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">decisions</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">expit</span>  <span class="c1"># 사이파이 모듈에서 제공하는 시그모이드 함수
</span><span class="k">print</span><span class="p">(</span><span class="n">expit</span><span class="p">(</span><span class="n">decisions</span><span class="p">))</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]
       [0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
</code></pre></div></div>
:ET