I"2x<p>본 포스팅은 “혼자 공부하는 머신러닝+딥러닝” 책 내용을 기반으로 작성되었습니다.
잘못된 내용이 있을 경우 지적해 주시면 감사드리겠습니다.</p>

<h2 id="6-1-가중치-시각화">6-1. 가중치 시각화</h2>
<p>합성곱 층은 여러 개의 필터를 사용해 이미지에서 특징을 학습한다. 각 필터는 커널이라 부르는 가중치와 절편을 갖는다. 절편은 사실 시각적으로 의미가 있지는 않다. 가중치는 입력 이미지의 2차원 영역에 적용되어 어떤 특징을 크게 두드러지게 표현하는 역할을 한다.<br />
만약 둥근 모서리를 뽑아내는 필터가 있다고 하자. 이 필터의 가중치는 둥근 모서리가 있는 영역에서 크게 활성화 되고, 그렇지 않은 영역에서는 낮은 값을 만든다. 즉, 곡선 부분의 가중치 값은 높고, 그 외 부분의 가중치 값는 낮을 것이다.<br />
5장에서 만든 모델을 불러오자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">'best-cnn-model.h5'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">layers</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) [&lt;tensorflow.python.keras.layers.convolutional.Conv2D at 0x245e6418f28&gt;,
       &lt;tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x245e6447860&gt;,
       &lt;tensorflow.python.keras.layers.convolutional.Conv2D at 0x245e6487ba8&gt;,
       &lt;tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x245e66b23c8&gt;,
       &lt;tensorflow.python.keras.layers.core.Flatten at 0x245e66b26a0&gt;,
       &lt;tensorflow.python.keras.layers.core.Dense at 0x245e66bc320&gt;,
       &lt;tensorflow.python.keras.layers.core.Dropout at 0x245e66bc710&gt;,
       &lt;tensorflow.python.keras.layers.core.Dense at 0x245e66bce48&gt;]
</code></pre></div></div>

<p>첫 번째 합성곱 층의 가중치를 보자. 층의 가중치와 절편은 <code class="language-plaintext highlighter-rouge">weights</code> 속성에 저장되어 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">conv</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">conv</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span> <span class="n">conv</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (3, 3, 1, 32) (32,)
</code></pre></div></div>

<p>커널 크기가 3x3 이었고, 입력의 깊이는 1이었다. 출력 필터 개수가 32개 였으므로 올바르게 출력되었다는 것을 확인할 수 있다. 필터마다 1개의 절편이 있으므로 절편도 32개가 맞다. weights 속성은 다차원 배열인 Tensor 클래스의 객체이다. 다루기 쉽도록 <code class="language-plaintext highlighter-rouge">numpy()</code> 메소드로 넘파이 배열로 변환하고 가중치 배열의 평균과 표준편차를 구해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">conv_weights</span> <span class="o">=</span> <span class="n">conv</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">conv_weights</span><span class="p">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">conv_weights</span><span class="p">.</span><span class="n">std</span><span class="p">())</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) -0.009519433 0.23307213
</code></pre></div></div>

<p>가중치의 평균이 0에 가깝고, 표준편차는 0.23 정도이다. 이 가중치가 어떤 분포를 가졌는지 확인해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">conv_weights</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># (288, 1)
</span><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'weight'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'count'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">,</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/6-1.png" alt="그림 6-1. 코드 결과" /></p>
<p>그림 6-1. 코드 결과</p>

<p><code class="language-plaintext highlighter-rouge">hist()</code> 함수로 히스토그램을 그리려면 1차원 배열이 전달되어야 한다. 히스토그램을 보면 0을 중심으로 종 모양 분포를 띠고 있음을 볼 수 있다. 이 점을 일단 주목하자.<br />
이번에는 32개의 커널을 출력해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">16</span><span class="p">):</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">conv_weights</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="o">*</span><span class="mi">16</span><span class="o">+</span><span class="n">j</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/6-2.png" alt="그림 6-2. 코드 결과" /></p>
<p>그림 6-2. 코드 결과</p>

<p>밝은 부분의 값이 가장 높다할 수 있다. 첫 번째 줄의 맨 왼쪽 가중치는 오른쪽 3픽셀 값이 가장 높다. 이 가중치는 오른쪽에 놓인 직선을 만나면 크게 활성화 될 것이다. 참고로 <code class="language-plaintext highlighter-rouge">imshow()</code>의 <code class="language-plaintext highlighter-rouge">vmin</code>과 <code class="language-plaintext highlighter-rouge">vmax</code>는 절대값을 기준으로 픽셀의 강도를 나타내기 위해 사용했다. 즉 그 배열의 최대값이면 가장 밝은 노란색으로 그리는 것이다.<br />
이제 훈련하지 않은 빈 합성곱 신경망을 만들고, 이 합성곱의 가중치가 위 코드에서 본 훈련된 가중치와 어떻게 다른지 보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">no_training_model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">no_training_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">no_training_conv</span> <span class="o">=</span> <span class="n">no_training_model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">no_training_conv</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>

<span class="n">no_training_weights</span> <span class="o">=</span> <span class="n">no_training_conv</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">no_training_weights</span><span class="p">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">no_training_weights</span><span class="p">.</span><span class="n">std</span><span class="p">())</span>

<span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">no_training_weights</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'weight'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'count'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext align-center highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (3, 3, 1, 32)
       0.007826313 0.0833402 ![그림 6-3. 코드 결과](/assets/images/deeplearningtens/6-3.png)
</code></pre></div></div>
<p>그림 6-3. 코드 결과</p>

<p>확실히 이전과 다르다. 대부분의 가중치가 -0.15~0.15 사이에 비교적 고르게 분포하고 있다. 이런 모양인 이유는 바로 텐서플로가 신경망의 가중치를 처음 초기화할 때 균등 분포에서 랜덤하게 값을 선택하기 때문이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">16</span><span class="p">):</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">no_training_weights</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="o">*</span><span class="mi">16</span><span class="o">+</span><span class="n">j</span><span class="p">],</span> <span class="n">vmin</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/6-4.png" alt="그림 6-4. 코드 결과" /></p>
<p>그림 6-4. 코드 결과</p>

<p>전체적으로 필터의 가중치가 밋밋하게 초기화됐다. 이 그림을 훈련을 마친 가중치와 비교하면 합성곱 신경망이 패션 MIST 데이터셋의 분류 정확도를 높이기 위해 유용한 패턴을 학습했다는 것을 확인할 수 있다.</p>

<h2 id="6-2-함수형-api">6-2. 함수형 API</h2>
<p>만약 입력이 2개고 출력이 2개라면 지금까지 썼던 <code class="language-plaintext highlighter-rouge">Sequential()</code> 클래스를 사용하기 어렵다. 이 경우에는 <strong>함수형 API(Functional API)</strong>를 사용한다. 함수형 API는 케라스의 Model 클래스를 사용하여 모델을 만든다. 일단 Dense 층 2개를 만들어보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dense1</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)</span>
<span class="n">dense2</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
</code></pre></div></div>

<p>여기서 전에는 <code class="language-plaintext highlighter-rouge">Sequential()</code> 클래스의 <code class="language-plaintext highlighter-rouge">add()</code> 메소드에 위 객체들을 전달했다. 하지만 다음과 같이 함수처럼 호출도 가능하다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hidden</span> <span class="o">=</span> <span class="n">dense1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">dense2</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</code></pre></div></div>

<p>입력에서 출력까지 층을 호출한 결과를 계속 이어주고, Model 클래스에 입력과 최종 출력을 지정한다. 여기서 inputs은 어디서 왔을까? <code class="language-plaintext highlighter-rouge">Sequential()</code> 클래스는 <code class="language-plaintext highlighter-rouge">InputLayer</code> 클래스를 자동으로 추가하고 호출해 주었다. 하지만 <code class="language-plaintext highlighter-rouge">Model()</code> 클래스는 우리가 수동으로 <code class="language-plaintext highlighter-rouge">InputLayer</code> 클래스를 만들어 호출해야한다. 케라스는 <code class="language-plaintext highlighter-rouge">InputLayer</code>를 쉽게 다룰 수 있도록 <code class="language-plaintext highlighter-rouge">Input()</code> 함수를 별도로 제공한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Inputs</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,))</span>
</code></pre></div></div>

<p>참고로 케라스 모델은 <code class="language-plaintext highlighter-rouge">layers</code> 속성 외 InputLayer 객체를 포함한 <code class="language-plaintext highlighter-rouge">_layers</code> 속성을 따로 가지고 있다. <code class="language-plaintext highlighter-rouge">Sequential</code> 클래스 객체의 <code class="language-plaintext highlighter-rouge">_layers</code> 속성 첫 번째 항목이 바로 <code class="language-plaintext highlighter-rouge">InputLayer</code> 클래스의 객체이다. <code class="language-plaintext highlighter-rouge">InputLayer</code> 클래스는 모델의 입력을 첫 번째 은닉층에 전달하는 역할을 한다. 따라서 <code class="language-plaintext highlighter-rouge">InputLayer</code> 객체의 입력과 출력은 동일하다. 이제 전체를 합쳐보자!</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,))</span>
<span class="n">hidden</span> <span class="o">=</span> <span class="n">dense1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">dense2</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</code></pre></div></div>

<p>우리는 이제 특성 맵 시각화를 수행할 것이다. 그런데 이를 위해서는 함수형 API가 꼭 필요하다. 왜 일까?<br />
우리는 6-1 장의 모델에서 첫 번째 <code class="language-plaintext highlighter-rouge">Conv2D</code> 출력이 필요하다. 만약 6-1 장의 model 객체 입력과 <code class="language-plaintext highlighter-rouge">conv2D</code> 출력을 알 수 있다면, 이 둘을 연결하여 새로운 모델을 얻을 수 있을 것이다. 우리는 첫 번째 Conv2D 층이 출력한 특성 맵을 원한다. 첫 번째 층의 출력은 Conv2D 객체의 output 속성에서 얻을 수 있다. <code class="language-plaintext highlighter-rouge">model.layers[0].output</code> 처럼 참조가 가능하다. model 객체의 입력은 <code class="language-plaintext highlighter-rouge">input</code> 속성으로 입력을 참조할 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nb">input</span><span class="p">)</span>
<span class="n">conv_acti</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) Tensor("conv2d_4_input_2:0", shape=(None, 28, 28, 1), dtype=float32)
</code></pre></div></div>

<h2 id="6-3-특성-맵-시각화">6-3. 특성 맵 시각화</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">train_input</span><span class="p">,</span> <span class="n">train_target</span><span class="p">),</span> <span class="p">(</span><span class="n">test_input</span><span class="p">,</span> <span class="n">test_target</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">fashion_mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_input</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray_r'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/6-5.png" alt="그림 6-5. 코드 결과" /></p>
<p>그림 6-5. 코드 결과</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">train_input</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">feature_maps</span> <span class="o">=</span> <span class="n">conv_acti</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">feature_maps</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(결과) (1, 28, 28, 32)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">feature_maps</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span><span class="n">i</span><span class="o">*</span><span class="mi">8</span><span class="o">+</span><span class="n">j</span><span class="p">])</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p class="align-center"><img src="/assets/images/deeplearningtens/6-6.png" alt="그림 6-6. 코드 결과" /></p>
<p>그림 6-6. 코드 결과</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">conv2_acto</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">output</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">train_input</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">features_maps</span> <span class="o">=</span> <span class="n">conv_acti2</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">features_maps</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">feature_maps</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span><span class="n">i</span><span class="o">*</span><span class="mi">8</span><span class="o">+</span><span class="n">j</span><span class="p">])</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
:ET